{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import gseapy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from goatools import obo_parser\n",
    "import wget\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import mygene\n",
    "import numpy as np\n",
    "import collections\n",
    "import pycrosstalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_os = \"windows11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RCC = pd.read_csv(\"/home/larissa/Documents/Masterarbeit/RCC_results/liana_log_norm/no_subset_glom_removed/T_lr_ready.csv\", index_col=0)\n",
    "#MF = pd.read_csv(\"/home/larissa/Documents/Masterarbeit/MF_results/liana/all_celltypes/MF_lr_ready.csv\", index_col=0)\n",
    "\n",
    "#RCC = pd.read_csv(\"D:\\\\studium\\\\Masterarbeit\\\\RCC_results\\\\liana_log_norm\\\\no_subset_glom_removed\\\\T_lr_ready.csv\", index_col=0)\n",
    "#MF = pd.read_csv(\"D:\\\\studium\\\\Masterarbeit\\\\MF_results\\\\liana\\\\all_celltypes\\\\MF_lr_ready.csv\", index_col=0)\n",
    "\n",
    "\n",
    "RCC = pd.read_csv(\"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\RCC_results\\\\liana_log_norm\\\\no_subset_glom_removed\\\\T_lr_ready.csv\", index_col = 0)\n",
    "MF = pd.read_csv(\"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\MF_results\\\\liana\\\\all_celltypes\\\\MF_lr_ready.csv\", index_col = 0)\n",
    "\n",
    "\n",
    "RCC[\"lr_pair\"] = RCC[\"gene_A\"] + \"_\" + RCC[\"gene_B\"]\n",
    "MF[\"lr_pair\"] = MF[\"gene_A\"] + \"_\" + MF[\"gene_B\"]\n",
    "\n",
    "RCC[\"cluster_pair\"] = RCC[\"source\"] + \"@\" + RCC[\"target\"]\n",
    "MF[\"cluster_pair\"] = MF[\"source\"] + \"@\" + MF[\"target\"]\n",
    "\n",
    "RCC = RCC[~RCC.apply(lambda r: r.str.contains('Glomerular endothelium').any(), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abc3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBConfig res 1.25 after removing glom endo\n",
    "cluster_dict = {\"Monocytes\" : [\"MF_CD16_monocytes\", \"MF_Classical_monocytes\", \"MF_EBM_prog\", \"MF_GMPs\",\n",
    "    \"MF_Inflammatory_CD14_monocytes\", \"MF_Late_Neutro_Prog\", \"MF_Macrophages\",\n",
    "    \"MF_Neutrophils\", \"MF_SPP1_Macrophages\", \"MF_cDC1\", \"MF_cDC2\", \"RCC_Classical monocytes\", \"RCC_Non-classical monocytes\", \"RCC_TAM 1\", \"RCC_TAM 2\", \"RCC_TAM 3\", \"RCC_TAM 4\"],\n",
    "\"Lymphocytes\" : [\"MF_B_cells\", \"MF_CD8_T_cells\",\"MF_NK_T_cells\", \"RCC_B cells\",\n",
    "    \"RCC_CD8 T cells\", \"RCC_Cytotoxic T cells\", \"RCC_IGHG-high plasma cells\",\n",
    "    \"RCC_NK cells\", \"RCC_Plasma cells\", \"RCC_Regulatory T cells\",\n",
    "    \"RCC_Resting/memory T cells\"],#, \"RCC_Proximal tubule\"],\n",
    "\"Tumor_prog\" : [\"MF_B_cell_prog\", \"MF_Plasma_cells\",\n",
    "                 \"MF_Early_Neutro_Prog\", \"MF_HSPCs\", \"MF_MEPs\", \"MF_MK_prog\",\n",
    "    \"RCC_DCT/CNT\", \"RCC_Epithelial progenitor-like cells\", \"RCC_Principal cells\",\n",
    "    \"RCC_Tumor cells 1\", \"RCC_Tumor cells 2\", \"RCC_Tumor cells 3\", \"RCC_tAL of LOH\"],\n",
    "\"Endothelial\" : [ \"MF_pDCs\", \"MF_Arterial_EC\", \"MF_Erythroid_cells\", \"MF_Late_Erythroid_Prog\",\n",
    "    \"MF_Sinusoidal_EC\", \"RCC_AVR\", \"RCC_DVR\", \"RCC_Tumor AVR-like vasculature\",\n",
    "    \"RCC_Tumor vasculature 1\", \"RCC_Tumor vasculature 2\", \"RCC_Tumor vasculature 3\", \"RCC_Tumor vasculature 4\"],\n",
    "\"Stromal\" : [\"MF_Adipo_CAR\", \"MF_Mature_MKs\", \"MF_OLCs\", \"MF_Osteoblasts\", \"RCC_Mesangial/vSMCs\",\n",
    "    \"RCC_Myofibroblasts\", \"RCC_vSMCs\"],\n",
    "\"Mast_cells\" : [\"MF_Mast_cells\", \"RCC_Mast cells\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dicts(df, clusters, opt = \"all\"):\n",
    "\n",
    "        if opt == \"all\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) | df[\"target\"].isin(clusters)]\n",
    "        elif opt == \"intra\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) & df[\"target\"].isin(clusters)]\n",
    "            #sub_df = sub_df[sub_df[\"source\"] != sub_df[\"target\"]]\n",
    "        elif opt == \"inter\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) | df[\"target\"].isin(clusters)]\n",
    "            sub_df = sub_df[~((sub_df[\"source\"].isin(clusters)) & (sub_df[\"target\"].isin(clusters)))]\n",
    "        #print(sub_df)\n",
    "\n",
    "        source_dict = {cl: [] for cl in clusters}\n",
    "        target_dict = {cl: [] for cl in clusters}\n",
    "        \n",
    "        for _, row in sub_df.iterrows():\n",
    "            if row[\"source\"] in source_dict:\n",
    "                source_dict[row[\"source\"]].append(row[\"lr_pair\"])\n",
    "            if row[\"target\"] in target_dict:\n",
    "                target_dict[row[\"target\"]].append(row[\"lr_pair\"])\n",
    "        return source_dict, target_dict\n",
    "\n",
    "def threshold_intersection(sets_list, threshold):\n",
    "                \"\"\"Return elements appearing in at least threshold fraction of sets.\"\"\"\n",
    "                n_sets = len(sets_list)\n",
    "                min_count = max(1, int(threshold * n_sets))  # at least 1\n",
    "                counter = collections.Counter()\n",
    "                for s in sets_list:\n",
    "                    counter.update(s)\n",
    "                return {elem for elem, count in counter.items() if count >= min_count}\n",
    "\n",
    "    \n",
    "def build_dicts_associated_gene(df, clusters, opt = \"all\"):\n",
    "\n",
    "        if opt == \"all\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) | df[\"target\"].isin(clusters)]\n",
    "        elif opt == \"intra\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) & df[\"target\"].isin(clusters)]\n",
    "        elif opt == \"inter\":\n",
    "            sub_df = df[df[\"source\"].isin(clusters) | df[\"target\"].isin(clusters)]\n",
    "            sub_df = sub_df[~sub_df[\"source\"].isin(clusters) & sub_df[\"target\"].isin(clusters)]\n",
    "        source_dict = {cl: [] for cl in clusters}\n",
    "        target_dict = {cl: [] for cl in clusters}\n",
    "        \n",
    "        for _, row in sub_df.iterrows():\n",
    "            if row[\"source\"] in source_dict:\n",
    "                source_dict[row[\"source\"]].append(row[\"gene_A\"])\n",
    "            if row[\"target\"] in target_dict:\n",
    "                target_dict[row[\"target\"]].append(row[\"gene_B\"])\n",
    "        return source_dict, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a,b,c(set) 2a,b,c(threshold) 3a,b,c(unique)  get all interactions\n",
    "#replace c with LR-L(downstream)\n",
    "#d is the same as c but is returning source and target genes together (fix that receptor complexes still need to be split)\n",
    "#add empty lists so that singleton clusters dont repeat genes\n",
    "\n",
    "def get_interactions_set(opt = \"set\", opt2 = \"a\"):\n",
    "    all_interactions_list = []\n",
    "    all_interactions_source_list = []\n",
    "    all_interactions_target_list = []\n",
    "    unique_per_cluster = []\n",
    "    unique_per_cluster_source = []\n",
    "    unique_per_cluster_target = []\n",
    "    test_clust = []\n",
    "\n",
    "    for i in cluster_dict: \n",
    "        tst_clust = []\n",
    "        all_interactions = []\n",
    "        all_interactions_source = []\n",
    "        all_interactions_target = []\n",
    "        \n",
    "        #for clust in cluster_dict[i]:\n",
    "        #    if any(clust in vals for vals in stable_partners.values()):\n",
    "        #        tst_clust.append(clust)\n",
    "\n",
    "        for clust in cluster_dict[i]:\n",
    "            tst_clust.append(clust)\n",
    "            \n",
    "        print(tst_clust)\n",
    "        tst_clust = list(map(lambda x:  x.removeprefix(\"RCC_\").removeprefix(\"MF_\"), tst_clust))\n",
    "\n",
    "        if opt2 == \"a\" or opt2 == \"b\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust)\n",
    "\n",
    "        if opt2 == \"c\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust)\n",
    "\n",
    "            downstreamL_RCC, _ = build_dicts_associated_gene(RCC, tst_clust)\n",
    "            downstreamL_MF, _ = build_dicts_associated_gene(MF, tst_clust)\n",
    "\n",
    "        if opt2 == \"d\" or opt2 == \"d2\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts_associated_gene(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts_associated_gene(MF, tst_clust)\n",
    "\n",
    "        RCC_source_sets =  {cl: set(clust_dict_source_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_source_sets = {cl: set(clust_dict_source_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "\n",
    "        RCC_target_sets =  {cl: set(clust_dict_target_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_target_sets = {cl: set(clust_dict_target_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "\n",
    "        if opt == \"set\" or opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                \n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "\n",
    "            RCC_source_sets_interactions = []\n",
    "            RCC_target_sets_interactions = []\n",
    "            RCC_total_interactions = []\n",
    "            if len(RCC_target_sets) >= 1: \n",
    "                RCC_source_sets_interactions =  set.intersection(*RCC_source_sets.values())\n",
    "                RCC_target_sets_interactions =  set.intersection(*RCC_target_sets.values())\n",
    "                RCC_total_interactions = RCC_source_sets_interactions.union(RCC_target_sets_interactions)\n",
    "                #print(RCC_target_sets)\n",
    "                #print(RCC_target_sets_interactions)\n",
    "\n",
    "            MF_source_sets_interactions = []\n",
    "            MF_target_sets_interactions = []\n",
    "            MF_total_interactions = []\n",
    "            if len(MF_target_sets) >= 1: \n",
    "                MF_source_sets_interactions =  set.intersection(*MF_source_sets.values())\n",
    "                MF_target_sets_interactions =  set.intersection(*MF_target_sets.values())\n",
    "                MF_total_interactions = MF_source_sets_interactions.union(MF_target_sets_interactions)\n",
    "\n",
    "            if opt2 == \"a\" or opt2 ==\"d\":\n",
    "                if len(RCC_total_interactions) > 1 and len(MF_total_interactions) > 1: \n",
    "                    all_interactions = RCC_total_interactions.intersection(MF_total_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 == \"b\"  or opt2 == \"d2\":\n",
    "                if len(MF_source_sets_interactions) > 1 or len(RCC_source_sets_interactions) > 1: \n",
    "                    all_interactions_source = RCC_source_sets_interactions.intersection(MF_source_sets_interactions)\n",
    "                    all_interactions_target = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "                \n",
    "            if opt2 == \"c\":\n",
    "                if len(MF_target_sets_interactions) > 1 and len(RCC_target_sets_interactions) > 1: \n",
    "                    all_interactions = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                \n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "        ###########################################################################################################  \n",
    "        if opt == \"threshold\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                \n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "            RCC_source_sets_list = list(RCC_source_sets.values())\n",
    "            MF_source_sets_list = list(MF_source_sets.values())\n",
    "            RCC_target_sets_list = list(RCC_target_sets.values())\n",
    "            MF_target_sets_list = list(MF_target_sets.values())\n",
    "\n",
    "            threshold = 0.7  # 80%\n",
    "\n",
    "            source_interactions_RCC = threshold_intersection(RCC_source_sets_list, threshold) if len(RCC_source_sets_list) > 0 else set()\n",
    "            target_interactions_RCC = threshold_intersection(RCC_target_sets_list, threshold) if len(RCC_target_sets_list) > 0 else set()\n",
    "\n",
    "            source_interactions_MF = threshold_intersection(MF_source_sets_list, threshold) if len(MF_source_sets_list) > 0 else set()\n",
    "            target_interactions_MF = threshold_intersection(MF_target_sets_list, threshold) if len(MF_target_sets_list) > 0 else set()\n",
    "\n",
    "            all_interactions_RCC = source_interactions_RCC.union(target_interactions_RCC) if len(source_interactions_RCC) > 0 else set()\n",
    "            all_interactions_MF = source_interactions_MF.union(target_interactions_MF) if len(source_interactions_MF) > 0 else set()\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\":\n",
    "                all_interactions = all_interactions_RCC.intersection(all_interactions_MF) if (len(all_interactions_MF) > 0 & len(all_interactions_RCC)) else set()\n",
    "                #all_interactions = list(threshold_intersection([all_interactions_RCC, all_interactions_MF]) if len(all_interactions_MF) > 0 else set())\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "        \n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                if len(source_interactions_MF) > 1 or len(source_interactions_RCC) > 1: \n",
    "                    all_interactions_source = source_interactions_RCC.intersection(source_interactions_MF)\n",
    "                    all_interactions_target = target_interactions_RCC.intersection(target_interactions_MF)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 ==\"c\":\n",
    "                if len(target_interactions_MF) > 1 and len(target_interactions_RCC) > 1: \n",
    "                    all_interactions = target_interactions_RCC.intersection(target_interactions_MF)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                \n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "     \n",
    "    if opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\" or opt2 == \"c\":\n",
    "                for i, clustergenes in enumerate(all_interactions_list):\n",
    "                    #print(len(cluster))\n",
    "                    if len(clustergenes) > 0:\n",
    "                        #print(\"clustergenes\", clustergenes)\n",
    "                        set_i = set(clustergenes)  # interactions in this cluster\n",
    "                        #print(\"set_i\", set_i)\n",
    "                        others = set().union(*[all_interactions_list[j] for j in range(len(all_interactions_list)) if j != i])\n",
    "                        unique = set_i - others  # LRs only in this cluster\n",
    "                        #print(\"unique\", unique)\n",
    "                        unique_per_cluster.append(unique)\n",
    "                    else:\n",
    "                        unique_per_cluster.append(set())\n",
    "\n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                 \n",
    "                for i, cluster in enumerate(all_interactions_source_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_source_list[j] for j in range(len(all_interactions_source_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_source.append(unique)\n",
    "\n",
    "                for i, cluster in enumerate(all_interactions_target_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_target_list[j] for j in range(len(all_interactions_target_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_target.append(unique)\n",
    "\n",
    "\n",
    "    if opt2 == \"a\" or opt2 ==\"c\" or opt2 == \"d\":\n",
    "        if opt == \"set\" or opt == \"threshold\":        \n",
    "            return all_interactions_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            return unique_per_cluster, test_clust\n",
    "        \n",
    "    if opt2 == \"b\" or opt2 == \"d2\":\n",
    "        if opt == \"set\" or opt == \"threshold\":        \n",
    "            return all_interactions_source_list, all_interactions_target_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            return unique_per_cluster_source, unique_per_cluster_target, test_clust\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e == just clust1 -L-R- clust2\n",
    "#c2 is s= clust1-L-R-clust2 and t= just clust-L?? \n",
    "#a is clust1 -L-R-clust2-L-R-clust3\n",
    "def get_intra_inter(opt, opt2, opt3):\n",
    "    all_interactions_list = []\n",
    "    all_interactions_source_list = []\n",
    "    all_interactions_target_list = []\n",
    "    unique_per_cluster = []\n",
    "    unique_per_cluster_source = []\n",
    "    unique_per_cluster_target = []\n",
    "    test_clust = []\n",
    "    all_interactions_dict = {}\n",
    "\n",
    "    RCC_source_dict = {}\n",
    "    RCC_target_dict = {}\n",
    "    MF_source_dict = {}\n",
    "    MF_target_dict = {}\n",
    "    \n",
    "    for i in cluster_dict: \n",
    "        tst_clust = []\n",
    "        all_interactions = []\n",
    "        all_interactions_source = []\n",
    "        all_interactions_target = []\n",
    "        \n",
    "        for clust in cluster_dict[i]:\n",
    "            tst_clust.append(clust)\n",
    "            \n",
    "        print(tst_clust)\n",
    "        tst_clust = list(map(lambda x:  x.removeprefix(\"RCC_\").removeprefix(\"MF_\"), tst_clust))\n",
    "        \n",
    "        if opt3 == \"intra\":\n",
    "            if opt2 == \"a\" or opt2 ==\"a2\" or opt2 == \"b\" or opt2 ==\"e\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust, opt = \"intra\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust, opt = \"intra\")\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust, opt = \"intra\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust, opt = \"intra\")\n",
    "                \n",
    "                downstreamL_RCC, _ = build_dicts_associated_gene(RCC, tst_clust, opt = \"intra\")\n",
    "                downstreamL_MF, _ = build_dicts_associated_gene(MF, tst_clust, opt = \"intra\")\n",
    "\n",
    "            if opt2 == \"d\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts_associated_gene(RCC, tst_clust, opt = \"intra\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts_associated_gene(MF, tst_clust, opt = \"intra\")\n",
    "\n",
    "        elif opt3 == \"inter\":\n",
    "            if opt2 == \"a\"  or opt2 ==\"a2\" or opt2 == \"b\" or opt2 ==\"e\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust, opt = \"inter\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust, opt = \"inter\")\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust, opt = \"inter\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust, opt = \"inter\")\n",
    "\n",
    "                downstreamL_RCC, _ = build_dicts_associated_gene(RCC, tst_clust, opt = \"all\")\n",
    "                downstreamL_MF, _ = build_dicts_associated_gene(MF, tst_clust, opt = \"all\")\n",
    "\n",
    "            if opt2 == \"d\":\n",
    "                clust_dict_source_RCC, clust_dict_target_RCC = build_dicts_associated_gene(RCC, tst_clust, opt = \"inter\")\n",
    "                clust_dict_source_MF, clust_dict_target_MF = build_dicts_associated_gene(MF, tst_clust, opt = \"inter\")\n",
    "        #print(\"clust dict source RCC\", clust_dict_source_RCC)\n",
    "        RCC_source_sets =  {cl: set(clust_dict_source_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_source_sets = {cl: set(clust_dict_source_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "        #print(\"rcc source sets\", RCC_source_sets)\n",
    "        \n",
    "        RCC_target_sets =  {cl: set(clust_dict_target_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_target_sets = {cl: set(clust_dict_target_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "\n",
    "        if opt == \"set\" or opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                \n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "\n",
    "            RCC_source_sets_interactions = []\n",
    "            RCC_target_sets_interactions = []\n",
    "            RCC_total_interactions = []\n",
    "            if len(RCC_target_sets) >= 1: \n",
    "                RCC_source_sets_interactions =  set.intersection(*RCC_source_sets.values())\n",
    "                RCC_target_sets_interactions =  set.intersection(*RCC_target_sets.values())\n",
    "                RCC_total_interactions = RCC_source_sets_interactions.union(RCC_target_sets_interactions)\n",
    "                #print(RCC_target_sets)\n",
    "                #print(\"RCC_source_sets_interactions\", RCC_source_sets_interactions)\n",
    "                #print(\"RCC_target_sets_interactions\", RCC_target_sets_interactions)\n",
    "                \n",
    "\n",
    "            MF_source_sets_interactions = []\n",
    "            MF_target_sets_interactions = []\n",
    "            MF_total_interactions = []\n",
    "            if len(MF_target_sets) >= 1: \n",
    "                MF_source_sets_interactions =  set.intersection(*MF_source_sets.values())\n",
    "                MF_target_sets_interactions =  set.intersection(*MF_target_sets.values())\n",
    "                MF_total_interactions = MF_source_sets_interactions.union(MF_target_sets_interactions)\n",
    "                #print(\"MF_source_sets_interactions\", MF_source_sets_interactions)\n",
    "                #print(\"MF_target_sets_interactions\", MF_target_sets_interactions)\n",
    "            if opt2 == \"a\" or opt2 ==\"d\":\n",
    "                if len(RCC_total_interactions) > 1 and len(MF_total_interactions) > 1: \n",
    "                    all_interactions = RCC_total_interactions.intersection(MF_total_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 == \"b\"  or opt2 == \"d2\":\n",
    "                if len(MF_source_sets_interactions) > 1 or len(RCC_source_sets_interactions) > 1: \n",
    "                    all_interactions_source = RCC_source_sets_interactions.intersection(MF_source_sets_interactions)\n",
    "                    all_interactions_target = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "                \n",
    "            if opt2 == \"c\":\n",
    "                if len(MF_target_sets_interactions) > 1 and len(RCC_target_sets_interactions) > 1: \n",
    "                    all_interactions = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                \n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 == \"e\":\n",
    "                if len(MF_target_sets_interactions) > 1 and len(RCC_target_sets_interactions) > 1: \n",
    "                    all_interactions = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "            \n",
    "            #print(RCC_total_interactions, MF_total_interactions)\n",
    "            #print(RCC_target_sets_interactions, MF_target_sets_interactions)\n",
    "\n",
    "            if opt2 ==\"a2\":\n",
    "                \n",
    "                \n",
    "                RCC_source_dict[i] = RCC_source_sets_interactions\n",
    "                RCC_target_dict[i] = RCC_target_sets_interactions\n",
    "                MF_source_dict[i] = MF_source_sets_interactions\n",
    "                MF_target_dict[i] = MF_target_sets_interactions\n",
    "                test_clust.append(tst_clust)\n",
    "       \n",
    "\n",
    "        ###########################################################################################################  \n",
    "        if opt == \"threshold\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "                #print(\"rcc target sets\", RCC_target_sets)\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(\"MF target sets\", MF_target_sets)\n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "            RCC_source_sets_list = list(RCC_source_sets.values())\n",
    "            MF_source_sets_list = list(MF_source_sets.values())\n",
    "            RCC_target_sets_list = list(RCC_target_sets.values())\n",
    "            MF_target_sets_list = list(MF_target_sets.values())\n",
    "\n",
    "            threshold = 0.7  # %\n",
    "\n",
    "            source_interactions_RCC = threshold_intersection(RCC_source_sets_list, threshold) if len(RCC_source_sets_list) > 0 else set()\n",
    "            target_interactions_RCC = threshold_intersection(RCC_target_sets_list, threshold) if len(RCC_target_sets_list) > 0 else set()\n",
    "\n",
    "            source_interactions_MF = threshold_intersection(MF_source_sets_list, threshold) if len(MF_source_sets_list) > 0 else set()\n",
    "            target_interactions_MF = threshold_intersection(MF_target_sets_list, threshold) if len(MF_target_sets_list) > 0 else set()\n",
    "\n",
    "            all_interactions_RCC = source_interactions_RCC.union(target_interactions_RCC) if len(source_interactions_RCC) > 0 else set()\n",
    "            all_interactions_MF = source_interactions_MF.union(target_interactions_MF) if len(source_interactions_MF) > 0 else set()\n",
    "            #print(\"target interactions RCC\",target_interactions_RCC)\n",
    "            #print(\"target interactions MF\",target_interactions_MF)\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\":\n",
    "                all_interactions = all_interactions_RCC.intersection(all_interactions_MF) if (len(all_interactions_MF) > 0 & len(all_interactions_RCC)) else set()\n",
    "                #all_interactions = list(threshold_intersection([all_interactions_RCC, all_interactions_MF]) if len(all_interactions_MF) > 0 else set())\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "        \n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                if len(source_interactions_MF) > 1 or len(source_interactions_RCC) > 1: \n",
    "                    all_interactions_source = source_interactions_RCC.intersection(source_interactions_MF)\n",
    "                    all_interactions_target = target_interactions_RCC.intersection(target_interactions_MF)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 ==\"c\":\n",
    "                if len(target_interactions_MF) > 1 and len(target_interactions_RCC) > 1: \n",
    "                    all_interactions = target_interactions_RCC.intersection(target_interactions_MF)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "     ######################\n",
    "    if opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\" or opt2 == \"c\":\n",
    "                for i, clustergenes in enumerate(all_interactions_list):\n",
    "                    #print(len(cluster))\n",
    "                    if len(clustergenes) > 0:\n",
    "                        #print(\"clustergenes\", clustergenes)\n",
    "                        set_i = set(clustergenes)  # interactions in this cluster\n",
    "                        #print(\"set_i\", set_i)\n",
    "                        others = set().union(*[all_interactions_list[j] for j in range(len(all_interactions_list)) if j != i])\n",
    "                        unique = set_i - others  # LRs only in this cluster\n",
    "                        #print(\"unique\", unique)\n",
    "                        unique_per_cluster.append(unique)\n",
    "                    else:\n",
    "                        unique_per_cluster.append(set())\n",
    "\n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                 \n",
    "                for i, cluster in enumerate(all_interactions_source_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_source_list[j] for j in range(len(all_interactions_source_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_source.append(unique)\n",
    "\n",
    "                for i, cluster in enumerate(all_interactions_target_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_target_list[j] for j in range(len(all_interactions_target_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_target.append(unique)\n",
    "\n",
    "            if opt2 == \"a2\":\n",
    "                \n",
    "                source_dict_unique = {}\n",
    "                target_dict_unique = {}\n",
    "                \n",
    "                \n",
    "\n",
    "                if len(RCC_source_dict) > 1 and len(MF_source_dict) > 1:    \n",
    "                    source_dict = {\n",
    "                        cl: RCC_source_dict[cl].intersection(MF_source_dict.get(cl, set()))\n",
    "                        for cl in RCC_source_dict.keys()\n",
    "                    }\n",
    "\n",
    "            \n",
    "                if len(RCC_target_dict) > 1 and len(MF_target_dict) > 1:    \n",
    "                    target_dict = {\n",
    "                        cl: RCC_target_dict[cl].intersection(MF_target_dict.get(cl, set()))\n",
    "                        for cl in RCC_target_dict.keys()\n",
    "                    }\n",
    "\n",
    "                \n",
    "\n",
    "                for cl, genes in  source_dict.items():\n",
    "                    set_i = set(genes)  # interactions in this cluster\n",
    "                    #print(f\"set {cl}\", set_i)  \n",
    "                    others = set().union(*[source_dict[j] for j in source_dict if j != cl])\n",
    "                    #print(\"j\", [RCC_source_sets[j] for j in RCC_source_sets.keys() if j != cl])\n",
    "                    #print(\"others\", others)\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    #print(\"unique\", unique)\n",
    "                    source_dict_unique[cl] = unique\n",
    "\n",
    "            \n",
    "                for cl, genes in  target_dict.items():\n",
    "                    set_i = set(genes)  # interactions in this cluster\n",
    "                    #print(f\"set {cl}\", set_i)  \n",
    "                    others = set().union(*[target_dict[j] for j in target_dict if j != cl])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    #print(\"unique\", unique)\n",
    "                    target_dict_unique[cl] = unique\n",
    "\n",
    "                #print(source_dict)\n",
    "                #print(target_dict)\n",
    "\n",
    "                for cl, val in source_dict_unique.items():\n",
    "                    source_dict_unique[cl] = {item.split(\"_\", 1)[0] for item in source_dict_unique[cl]}\n",
    "\n",
    "                for cl in source_dict_unique.keys():\n",
    "                    all_interactions_list.append(source_dict_unique[cl].union(target_dict_unique[cl]))\n",
    "                            \n",
    "                #all_interactions_list = list(all_interactions_dict.values())\n",
    "\n",
    "                print(\"all interactions\", all_interactions_list)\n",
    "\n",
    "    if opt2 == \"a\" or opt2 ==\"c\" or opt2 == \"d\" or opt2 == \"e\":\n",
    "        if opt == \"set\" or opt == \"threshold\":     \n",
    "            print(\"all interactions\", all_interactions_list)   \n",
    "            return all_interactions_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            print(\"all interactions\", all_interactions_list)\n",
    "            return unique_per_cluster, test_clust\n",
    "        \n",
    "    if opt2 == \"a2\":\n",
    "        if opt == \"unique\":\n",
    "            return all_interactions_list, test_clust\n",
    "\n",
    "    if opt2 == \"b\" or opt2 == \"d2\":\n",
    "        if opt == \"set\" or opt == \"threshold\":        \n",
    "            return all_interactions_source_list, all_interactions_target_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            return unique_per_cluster_source, unique_per_cluster_target, test_clust\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3876430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ff, clusters_cleaned = get_interactions_set(opt =\"threshold\", opt2=\"c\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378f322",
   "metadata": {},
   "source": [
    "IFs: keratin (epithelial cells), vimentin (mesenchymal cells), desmin (muscle cells)?\n",
    "rcc: VHL gene inactivated; PAX8 expression, CD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GO_terms(opt = \"filter\"):\n",
    "    from goatools.obo_parser import GODag\n",
    "\n",
    "    go = GODag(\"go-basic.obo\")\n",
    "\n",
    "    anchors = {\n",
    "        \"Monocytes_Lymphocytes\": [\n",
    "            \"GO:0002376\", # immune system process\n",
    "            \"GO:0002520\", # immune system development\n",
    "            \"GO:0006955\", # immune response\n",
    "            \"GO:0030097\", # hemopoiesis\n",
    "            \"GO:0002764\", # immune response-regulating signaling pathway\n",
    "            \"GO:0002250\", # adaptive immune response\n",
    "            \"GO:0006665\" #sphingolipid  metabolic process\n",
    "        ],\n",
    "        \"Tumor_Prog\": [\n",
    "            \"GO:0007049\", # cell cycle\n",
    "            \"GO:0008283\", # cell proliferation\n",
    "            \"GO:0030154\", # cell differentiation\n",
    "            \"GO:0001837\", # epithelial to mesenchymal transition\n",
    "            \"GO:0001525\", # angiogenesis\n",
    "            \"GO:0001666\", # response to hypoxia,\n",
    "            \"GO:0002841\", #regulation of T cell mediated immune response to tumor cell\n",
    "            \"GO:0002347\", #response to tumor cell\n",
    "            \"GO:0002357\", # defense response to tumor cell\n",
    "            \"GO:0071228\", #cellular response to tumor cell,\n",
    "            \"GO:0008219\", #cell death\n",
    "            \"GO:0006914\", #autophagy\n",
    "            \"GO:0006281\", #DNA repair\n",
    "            \"GO:0007165\",  #signal transduction\n",
    "            \"GO:0002248\", #connective tissue replacement involved in inflammatory response wound healing\n",
    "            \"GO:0042060\", #wound healing\n",
    "            \"GO:1903747\", #positive regulation of fibronectin production\n",
    "            \"GO:0006986\", #response to unfolded protein\n",
    "            \"GO:0036503\" #ERAD pathway\n",
    "        ],\n",
    "        \"Kidney\": [\n",
    "            \"GO:0072001\", # renal system development\n",
    "            \"GO:0001822\", # kidney development\n",
    "            \"GO:0072073\", # kidney epithelial cell differentiation\n",
    "            \"GO:0072078\", # nephron development\n",
    "        ],\n",
    "        \"Endothelial\": [\n",
    "            \"GO:0001944\", # vasculature development\n",
    "            \"GO:0001525\", # angiogenesis\n",
    "            \"GO:0001568\", # blood vessel development\n",
    "            \"GO:0003018\", # vascular process in circulatory system\n",
    "        ],\n",
    "        \"Stromal_Bone\": [\n",
    "            \"GO:0001501\", # skeletal system development\n",
    "            \"GO:0001649\", # osteoblast differentiation\n",
    "            \"GO:0030198\", # extracellular matrix organization\n",
    "            \"GO:0043062\", # extracellular structure organization\n",
    "            \"GO:0048659\", #smooth muscle cell proliferation\n",
    "            \"GO:0003012\", # muscle system process \n",
    "            \"GO:0048762\", # mesenchymal cell differentiation\n",
    "            \"GO:0007155\", #cell adhesion\n",
    "            \"GO:0098645\", #collagen network\n",
    "            \"GO:0005581\", #collagen trimer\n",
    "            \"GO:0001503\",#ossification\n",
    "            \"GO:0060612\" #adipose tissue development\n",
    "        ],\n",
    "        \"MFs\": [\n",
    "            \"GO:0005126\", # cytokine receptor binding\n",
    "            \"GO:0031723\", #chemokine receptor binding: \n",
    "            \"GO:0003823\", #antigen binding\n",
    "            \"GO:0015036\", #oxidoreductase activity\n",
    "            \"GO:0000155\", #kinase activity\n",
    "            \"GO:0000121\", #phosphatase activity\n",
    "            \"GO:0005520\", #growth factor binding:\n",
    "            \"GO:0048018\", #receptor ligand activity\n",
    "            \"GO:0000981\", #DNA-binding transcription factor activity\n",
    "            \"GO:0005518\", #collagen binding\n",
    "            \"GO:0046810\", #extracellular matrix binding\n",
    "            \"GO:0034987\", #immunoglobulin receptor binding\n",
    "            \"GO:0008201\", #heparin binding:\n",
    "            \"GO:0005125\", #cytokine activity\n",
    "            \"GO:0005260\", #intracellularly ATP-gated chloride channel activity\n",
    "            \"GO:0005201\", #extracellular matrix structural constituent\n",
    "            \"GO:0008191\", #metalloendopeptidase activity\n",
    "            \"GO:0005546\", #phosphatidylinositol-4,5-bisphosphate binding\n",
    "            \"GO:0004222\", #cysteine-type endopeptidase activity\tECM degradation during remodeling\n",
    "            \"GO:0008237\",\t#metallopeptidase activity\n",
    "            \"GO:0019961\" #interferon binding\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    from goatools.associations import read_gaf\n",
    "\n",
    "\n",
    "    # Load annotations (GAF file, e.g. human gene2go)\n",
    "    #gene2go = read_gaf(\"goa_human.gaf\")  # download from EBI/GOA\n",
    "\n",
    "    # Count genes per GO term\n",
    "    #go_counts = {go_id: len(genes) for go_id, genes in gene2go.items()}\n",
    "\n",
    "    #print(\"GO:0001944 has\", go_counts.index(\"0001944\"))\n",
    "\n",
    "    def get_children(go_ids):\n",
    "        terms = set()\n",
    "        terms_children = set()\n",
    "        for go_id in go_ids:\n",
    "            if go_id in go:\n",
    "                terms.add(go_id)\n",
    "                terms.update(go[go_id].get_all_children())\n",
    "                terms_children.update(go[go_id].get_all_children())\n",
    "        return terms\n",
    "\n",
    "    # collect all terms across categories\n",
    "    allowed_terms = set()\n",
    "    for category, go_ids in anchors.items():\n",
    "        allowed_terms.update(get_children(go_ids))\n",
    "    print(len(allowed_terms))\n",
    "\n",
    "    if opt == \"filter\":\n",
    "        def load_annotations_from_gaf(path):\n",
    "            \"\"\"Load a GAF file (can be gzipped). Returns:\n",
    "            - gene_to_go: dict[gname] -> set(GO IDs)\n",
    "            - go_to_genes: dict[go] -> set(gname)\n",
    "            Uses DB_Object_Symbol (col 3, zero-based index 2) as gene/key and GO_ID (col 5, index 4).\n",
    "            \"\"\"\n",
    "            df = pd.read_csv(path, sep='\\t', comment='!', header=None, dtype=str)\n",
    "            # ensure at least 5 columns\n",
    "            df = df.loc[:, [2,4]].dropna()\n",
    "            df.columns = ['gene','go']\n",
    "            gene_to_go = df.groupby('gene')['go'].agg(lambda s: set(s)).to_dict()\n",
    "            go_to_genes = df.groupby('go')['gene'].agg(lambda s: set(s)).to_dict()\n",
    "            return gene_to_go, go_to_genes\n",
    "\n",
    "\n",
    "        def count_term_size(go_to_genes):\n",
    "            \"\"\"Global term size (unique genes per GO)\"\"\"\n",
    "            return {go: len(genes) for go, genes in go_to_genes.items()}\n",
    "\n",
    "        gene_to_go, go_to_genes = load_annotations_from_gaf(\"goa_human.gaf\")\n",
    "\n",
    "        term_sizes = count_term_size(go_to_genes)\n",
    "        filtered_terms = {go for go, n in term_sizes.items() if n <=400}\n",
    "\n",
    "        allowed_terms = allowed_terms.intersection(go_to_genes.keys())\n",
    "        print(len(allowed_terms))\n",
    "\n",
    "        filtered_out_terms = ['cardiac muscle cell differentiation', 'lung vasculature development',\n",
    "                      \"antigen processing and presentation\", \"cell differentiation\", \"positive regulation of gene expression\", \n",
    "                      #\"positive regulation of cell population proliferation\",\n",
    "                      \"inflammatory response\", \"signal transduction\", \n",
    "                      \"innate immune response\", \"immune response\", \"immune system process\",\"adaptive immune response\", \n",
    "                      \"cell population proliferation\", \"lung epithelial cell differentiation\", \"microglial cell activation\", \n",
    "                      \"astrocyte activation involved in immune response\", \"microglia development\", \"complement activation\", \n",
    "                      \"complement activation, classical pathway\", \"complement activation, lectin pathway\", \n",
    "                      \"complement activation, alternative pathway\", \"complement activation, GZMK pathway\", #\n",
    "                      \"complement receptor mediated signaling pathway\", \"neurogenesis\", \"microglial cell activation involved in immune response\", \n",
    "                      'immune effector process', 'cardiac muscle cell myoblast differentiation', 'kidney development', 'ureteric bud development',\n",
    "                      'retina vasculature development in camera-type eye', 'glial cell proliferation', 'inner ear auditory receptor cell differentiation',\n",
    "                      'neuroendocrine cell differentiation', 'aorta development', #'glial cell differentiation', \n",
    "                      'coronary vasculature development', \"neuron differentiation\", \"dopaminergic neuron differentiation\", \n",
    "                      'endocardial cushion to mesenchymal transition', 'epithelial to mesenchymal transition involved in endocardial cushion formation', \n",
    "                      'angiogenesis involved in coronary vascular morphogenesis', 'cerebellar granule cell precursor proliferation', \n",
    "                      \"neural precursor cell proliferation\", 'negative regulation of blood-brain barrier permeability',\n",
    "                      'Bergmann glial cell differentiation', 'type II pneumocyte differentiation', 'type I pneumocyte differentiation', \"microglial cell differentiation\", \n",
    "                      'Cajal-Retzius cell differentiation', \"neuroblast proliferation\", \"T cell differentiation in thymus\", \"odontoblast differentiation\",\n",
    "                      \"cardiac epithelial to mesenchymal transition\", \"cardiac muscle contraction\", \"central nervous system vasculogenesis\", \n",
    "                      \"calcineurin-mediated signaling\", \"calcium-mediated signaling\", \"apoptotic process\", 'Sertoli cell differentiation', \"cell adhesion\",\n",
    "                      \"G protein-coupled receptor signaling pathway\"]\n",
    "\n",
    "    return allowed_terms, filtered_out_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_go_mapping_stats(res, all_genes):\n",
    "    \"\"\"\n",
    "    Prints summary statistics on how many genes were successfully mapped to GO terms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res : list\n",
    "        Result of mygene.MyGeneInfo().querymany() call.\n",
    "    all_genes : list\n",
    "        List of all input genes (symbols) that were queried.\n",
    "    \"\"\"\n",
    "    mapped_genes = set()\n",
    "    unmapped_genes = set(all_genes)\n",
    "\n",
    "    for r in res:\n",
    "        if \"go\" in r and r.get(\"entrezgene\") is not None:\n",
    "            symbol = r.get(\"symbol\", r.get(\"query\"))\n",
    "            mapped_genes.add(symbol)\n",
    "            if symbol in unmapped_genes:\n",
    "                unmapped_genes.remove(symbol)\n",
    "\n",
    "    print(\"GO Mapping\")\n",
    "    print(f\"Total genes: {len(all_genes)}\")\n",
    "    print(f\"Number of mapped genes: {len(mapped_genes)}\")\n",
    "    print(f\"Number of unmapped genes: {len(unmapped_genes)}\")\n",
    "    print(f\"Percentage mapped: {len(mapped_genes)/len(all_genes)*100:.2f}%\")\n",
    "    #print(\"\\nMapped genes:\", list(mapped_genes))\n",
    "    print(\"Unmapped genes:\", list(unmapped_genes))\n",
    "\n",
    "    return mapped_genes, unmapped_genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ripped from pycrosstalker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.colors as pc\n",
    "import plotly.graph_objects as go\n",
    "from plotnine import *\n",
    "from adjustText import adjust_text\n",
    "from gprofiler import GProfiler\n",
    "from sankeyflow import Sankey\n",
    "import json\n",
    "\n",
    "def plot_sankey_half(lrobj_tbl, target = None, ligand_cluster = None, receptor_cluster = None, plt_name = None, threshold = 50, tfflag = True):\n",
    "    \"\"\"\n",
    "    This function selected genes sankey plot\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    lrobj_tbl :\n",
    "        LRobject table with all data\n",
    "\n",
    "    target :\n",
    "        gene\n",
    "\n",
    "    ligand_cluster :\n",
    "        Ligand Clusters\n",
    "\n",
    "    receptor_cluster :\n",
    "        Receptor Clusters\n",
    "\n",
    "    plt_name :\n",
    "        plot title\n",
    "\n",
    "    threshold :\n",
    "        top_n n value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Python default plot\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    lrobj_tbl = lrobj_tbl[(lrobj_tbl['type_gene_A'] == \"Ligand\") & (lrobj_tbl['type_gene_B'] == \"Receptor\")]\n",
    "\n",
    "    if target is not None:\n",
    "        if len(target.split('|')) > 1:\n",
    "            target_type = str(target.split('|')[1])\n",
    "            if target_type == 'R':\n",
    "                if lrobj_tbl['gene_B'].str.contains('\\\\|').any():\n",
    "                    pass\n",
    "                else:\n",
    "                    target = target.split('|')[0]\n",
    "                data = lrobj_tbl[lrobj_tbl['gene_B'] == target]\n",
    "            elif target_type == 'L':\n",
    "                if lrobj_tbl['gene_A'].str.contains('\\\\|').any():\n",
    "                    pass\n",
    "                else:\n",
    "                    target = target.split('|')[0]\n",
    "                data = lrobj_tbl[lrobj_tbl['gene_A'] == target]\n",
    "        else:\n",
    "            data = lrobj_tbl[lrobj_tbl['allpair'].str.contains(target)]\n",
    "    else:\n",
    "        data = lrobj_tbl\n",
    "\n",
    "    \n",
    "    if ligand_cluster is not None:\n",
    "        data = data[data['source'].isin(ligand_cluster)]\n",
    "    \n",
    "    if receptor_cluster is not None:\n",
    "        data = data[data['target'].isin(receptor_cluster)]\n",
    "\n",
    "\n",
    "    color_palette = ['#00BFC4', '#FF3E3E']\n",
    "\n",
    "    \n",
    "    if len(data) >= 1:\n",
    "        cat_cols = ['source', 'gene_A']\n",
    "        value_cols = 'LRScore'\n",
    "        data = data.loc[data['LRScore'].abs().nlargest(min(len(data), threshold)).index]\n",
    "        title = plt_name\n",
    "\n",
    "        gen_sankey(data, cat_cols, value_cols, title)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Gene->{target} Not Found\")\n",
    "    \n",
    "\n",
    "def gen_sankey(df, cat_cols=[], value_cols='', title='Sankey Diagram'):\n",
    "    \"\"\"\n",
    "    Helper function to the function plot_sankey()\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        Dataframe\n",
    "\n",
    "    cat_cols :\n",
    "        Columns interested in the sankey plot\n",
    "\n",
    "    value_cols :\n",
    "        Sankey plot generated using connections based on this value_cols\n",
    "\n",
    "    title :\n",
    "        Title of Sankey plot\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing (plots Sankey plot)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # df['source'] += 'S'\n",
    "    df['target'] += ' '\n",
    "    \n",
    "    labelList = []\n",
    "    for catCol in cat_cols:\n",
    "        labelListTemp =  list((df[catCol].values))\n",
    "        labelList = labelList + labelListTemp    \n",
    "        \n",
    "    for i in range(len(cat_cols)-1):\n",
    "        if i==0:\n",
    "            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            sourceTargetDf.columns = ['source','target','count']\n",
    "        else:\n",
    "            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            tempDf.columns = ['source','target','count']\n",
    "            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "    \n",
    "    vmin = sourceTargetDf['count'].min()\n",
    "    vmax = sourceTargetDf['count'].max()\n",
    "    limit = max(abs(vmin), abs(vmax))\n",
    "    vcenter = 0\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-limit, vcenter=vcenter, vmax=limit)\n",
    "    # norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = plt.get_cmap('RdBu_r')\n",
    "    sourceTargetDf['hex_color'] = sourceTargetDf['count'].apply(lambda x: mcolors.to_hex(cmap(norm(x))))\n",
    "    \n",
    "    flows = []\n",
    "    for i, row in sourceTargetDf.iterrows():\n",
    "        flows.append((row['source'], row['target'], 1, {'color': row['hex_color']}))\n",
    "\n",
    "    nodes = Sankey.infer_nodes(flows)\n",
    "    nodes_new = []\n",
    "    for level in nodes:\n",
    "        level_new = []\n",
    "        for node in level:\n",
    "            node_new = node + [{'color' : 'black',\n",
    "                                'label_pos':'center', 'label_opts': dict(fontsize=10, bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))}]\n",
    "            level_new.append(node_new)\n",
    "        nodes_new.append(level_new)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    s = Sankey(flows=flows,\n",
    "               nodes=nodes_new,\n",
    "               flow_color_mode_alpha=0.3,\n",
    "               node_opts=dict(label_format='{label}'),\n",
    "    )\n",
    "    s.draw(ax=ax)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', pad=0.01, shrink=0.5)\n",
    "    cbar.set_label(value_cols, fontsize=12)\n",
    "\n",
    "    ax.text(x=0.0, y=1.02, s=\"Source\", fontsize=10)\n",
    "    ax.text(x=1.0, y=1.02, s=\"Ligand\", fontsize=10)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2849db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GO(f):\n",
    "    \n",
    "\n",
    "    allowed_terms, filtered_out_terms = get_GO_terms()\n",
    "\n",
    "    clusters = list(cluster_dict.values())\n",
    "\n",
    "    all_interactions = f\n",
    "    df_full = pd.DataFrame() \n",
    "    genes_bps_sep = {}\n",
    "    top_terms_list = []\n",
    "    top_terms_list_MF = []\n",
    "    for i in range(len(all_interactions)):\n",
    "        markers_tst = list(all_interactions[i])\n",
    "\n",
    "        s = \"_\"\n",
    "        clust_name = s.join(clusters[i]).replace(\"/\", \"_\")\n",
    "        print(clust_name)\n",
    "        print(clusters[i])\n",
    "        pre_genes = []\n",
    "        for m in markers_tst:\n",
    "            splitt = m.split(\"_\")\n",
    "            pre_genes.append(splitt)\n",
    "\n",
    "        genes = []\n",
    "        for xs in pre_genes:\n",
    "            for x in xs:\n",
    "                genes.append(x)\n",
    "                \n",
    "        genes = list(np.unique(genes))\n",
    "\n",
    "        mg = mygene.MyGeneInfo()\n",
    "\n",
    "        res = mg.querymany(\n",
    "            genes,\n",
    "            scopes=\"symbol\",\n",
    "            fields=\"entrezgene,ensembl.gene,go\",\n",
    "            species=\"human\"\n",
    "        )\n",
    "\n",
    "        rows = []\n",
    "        for r in res:\n",
    "            geneid = r.get(\"entrezgene\")\n",
    "            genename = r.get(\"symbol\", r[\"query\"]) \n",
    "            if geneid is None or \"go\" not in r:\n",
    "                continue\n",
    "            gos = r[\"go\"]\n",
    "            if isinstance(gos, dict):\n",
    "                for ns, terms in gos.items():  # ns = BP, MF, CC\n",
    "                    if isinstance(terms, list):\n",
    "                        for t in terms:\n",
    "                            rows.append({\"Gene\": genename, \"GeneID\": geneid, \"GOID\": t[\"id\"], \"Namespace\": ns, \"GOName\": t[\"term\"]})\n",
    "                    elif isinstance(terms, dict):\n",
    "                        rows.append({\"Gene\": genename, \"GeneID\": geneid, \"GOID\": terms[\"id\"], \"Namespace\": ns, \"GOName\": terms[\"term\"]})\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if not df.empty:\n",
    "            df = df[df[\"GOID\"].isin(allowed_terms)]\n",
    "            df = df[~df[\"GOName\"].isin(filtered_out_terms)]\n",
    "            #df = df[df[\"GOName\"].str.contains(\"pathway\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"cardiac\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"lens\")==False]\n",
    "            #df = df[df[\"GOName\"].str.contains(\"thymic\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"neural\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"neuron\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"brain\")==False]\n",
    "            df = df[df[\"GOName\"].str.contains(\"Langerhans\")==False]\n",
    "            genes_bps_tmp = df.groupby(\"GOName\")[\"Gene\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "        genes_bps_sep[i] = genes_bps_tmp\n",
    "        df_full = pd.concat((df_full, df))\n",
    "\n",
    "        if df.empty:\n",
    "            top_terms_list.append(set())\n",
    "            top_terms_list_MF.append(set())\n",
    "            continue\n",
    "\n",
    "        go_counts = df.groupby([\"Namespace\", \"GOID\", \"GOName\"]).count().rename(columns={\"GeneID\": \"GeneCount\"}).reset_index()\n",
    "\n",
    "        print(pre_genes)\n",
    "        unique_pairs = df[[\"Gene\", \"GOName\"]].drop_duplicates()\n",
    "        for gene, go in zip(unique_pairs[\"Gene\"], unique_pairs[\"GOName\"]):\n",
    "            print(gene, \"\", go)\n",
    "\n",
    "        mapped_genes, unmapped_genes = print_go_mapping_stats(res, genes)\n",
    "        \n",
    "        for ns in [\"BP\", \"MF\", \"CC\"]:\n",
    "        \n",
    "            top_terms = go_counts[go_counts.Namespace==ns].sort_values(\"GeneCount\", ascending=False)\n",
    "            top_terms_plot = go_counts[go_counts.Namespace==ns].sort_values(\"GeneCount\", ascending=False).head(30)\n",
    "            \n",
    "            plt.figure(figsize=(10,6))\n",
    "            sns.barplot(\n",
    "                data=top_terms_plot,\n",
    "                y=\"GOName\",\n",
    "                x=\"GeneCount\",\n",
    "                palette=\"viridis\"\n",
    "            )\n",
    "            if ns == \"BP\":\n",
    "                top_terms_list.append(top_terms[\"GOName\"])\n",
    "            elif ns == \"MF\":\n",
    "                top_terms_list_MF.append(top_terms[\"GOName\"])\n",
    "\n",
    "            plt.xlabel(\"Number of Genes\")\n",
    "            plt.ylabel(f\"GO {ns} Terms\")\n",
    "            #plt.title(f\"{clust_name}\")\n",
    "            plt.tight_layout()\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1a_common_LRs_cluster_all_LR_pairs_unchanged/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1b_common_LRs_cluster_separate_incoming_outgoing/incoming/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1b_common_LRs_cluster_separate_incoming_outgoing/outgoing/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/incoming/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/outgoing/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/set/RBERVertex/{clust_name}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/RBConfig_1_25/set/c/{clusters[i][0]}_top_30_BPs_GO.png\")\n",
    "            #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/endgame/CPM_0_31/unique/c/{clusters[i][0]}_top_30_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\RBConfig_1_25\\\\threshold\\\\c\\\\{clusters[i][0]}_top_30_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\RBConfig_1_25\\\\set\\\\c\\\\{clusters[i][0]}_top_30_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform\\\\set\\\\RBERVertex\\\\unique\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res025\\\\unique\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res031\\\\unique_c\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "            #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res031\\\\unique_d\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "            plt.show()\n",
    "    return df_full, top_terms_list, top_terms_list_MF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_bp_sankeys(f, clusters_cleaned, df_full, top_terms_list, intra_inter, which_os = \"linux\", cluster_dict = cluster_dict, overview = None, experimental = None):    \n",
    "\n",
    "    def flatten(xss):\n",
    "        return [x for xs in xss for x in xs]\n",
    "    \n",
    "    all_interactions = f\n",
    "    clusters = list(cluster_dict.values())\n",
    "    #print(df_full)\n",
    "    df_full_bp = df_full[df_full[\"Namespace\"] == \"BP\"]\n",
    "    df_full_bp = df_full_bp[[\"Gene\", \"GOName\"]]\n",
    "    \n",
    "    #df_full_bp.pivot(index=\"GOName\", columns=\"Gene\")\n",
    "    genes_bps = df_full_bp.groupby(\"GOName\")[\"Gene\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "    #get bp terms that only appear in one single cluster\n",
    "    unique_per_cluster = []\n",
    "\n",
    "    #the <2 not important here, just didnt delete bc i copied it from the unique genes function\n",
    "    for i, cluster in enumerate(top_terms_list):\n",
    "        if len(clusters[i]) < 1:\n",
    "            unique_per_cluster.append([])\n",
    "            continue\n",
    "        set_i = set(cluster)  # interactions in this cluster\n",
    "        others = set().union(*[top_terms_list[j]for j in range(len(top_terms_list)) if j != i])\n",
    "        unique = set_i - others  # LRs only in this cluster\n",
    "        unique_per_cluster.append(unique)\n",
    "\n",
    "    for idx, uniq in enumerate(unique_per_cluster):\n",
    "        cluster_key = list(cluster_dict.keys())[idx]\n",
    "        print(f\"{cluster_key}: {uniq}\")\n",
    "\n",
    "    genes_bps_sub = genes_bps[genes_bps.index.isin(flatten(unique_per_cluster))]\n",
    "\n",
    "\n",
    "    #doesnt check if lr pair is in cluster if using methods 1c where genes are already split\n",
    "    #knnen einfach einzeln da sein\n",
    "    method= \"d\"\n",
    "\n",
    "    interactions_in_bp = {}\n",
    "    interaction_genes_only = {}\n",
    "\n",
    "\n",
    "    for i, lr_sets in enumerate(all_interactions):\n",
    "        if not (lr_sets):\n",
    "            continue\n",
    "        cluster_hits = []\n",
    "        interaction_genes = []\n",
    "        #print(unique_per_cluster[i])\n",
    "        for j in unique_per_cluster[i]:\n",
    "            \n",
    "            bps_of_interest = [j]\n",
    "\n",
    "            #print(bps_of_interest)\n",
    "            genes_bps_sub = genes_bps[genes_bps.index.isin(bps_of_interest)]\n",
    "            #print(genes_bps_sub)\n",
    "            \n",
    "            \n",
    "            for interaction in lr_sets:\n",
    "                # split lr into ligand and receptor\n",
    "                if \"_\" in interaction:\n",
    "                    genes = interaction.split(\"_\")\n",
    "                else:\n",
    "                    genes = [interaction]\n",
    "                #print(genes)\n",
    "                for bp, genes_in_bp in genes_bps_sub.items():\n",
    "                    if not isinstance(genes_in_bp, set):\n",
    "                        genes_in_bp = set(genes_in_bp)\n",
    "\n",
    "                    #print(genes_in_bp)\n",
    "                    # are both l and r in this biological process\n",
    "                    matching = [g for g in genes if g in genes_in_bp]\n",
    "                    #matching = [(g, \"ligand\" if idx==0 else \"receptor\") \n",
    "                    #     for idx, g in enumerate(genes) if g in genes_in_bp]\n",
    "                    #print(matching)\n",
    "                    # if both ligand and receptor are in this BP then keep\n",
    "                    if method == \"d\":\n",
    "                        if len(matching) >= 1:  \n",
    "                            cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                            interaction_genes.append(interaction)\n",
    "\n",
    "                    else:\n",
    "                        if len(matching) >= 2:  \n",
    "                            cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                            interaction_genes.append(interaction)\n",
    "\n",
    "        interactions_in_bp[i] = cluster_hits\n",
    "        interaction_genes_only[i] = interaction_genes\n",
    "\n",
    "\n",
    "    for i, val in interaction_genes_only.items():\n",
    "        print(len(set(val)))\n",
    "\n",
    "    import contextvars\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects import pandas2ri, default_converter\n",
    "    from rpy2.robjects.conversion import localconverter, set_conversion\n",
    "\n",
    "    if which_os == \"windows11\":\n",
    "        # Initialize rpy2 conversion system\n",
    "        set_conversion(default_converter)\n",
    "\n",
    "        # Copy current context to propagate conversion settings into threads\n",
    "        ctx = contextvars.copy_context()\n",
    "\n",
    "        def load_diff_table(path: str):\n",
    "            def _read():\n",
    "                readRDS = ro.r['readRDS']\n",
    "                df = readRDS(path)\n",
    "                tables = df.slots['tables']\n",
    "\n",
    "                diff_table = tables[2]\n",
    "                with localconverter(default_converter + pandas2ri.converter):\n",
    "                    return ro.conversion.rpy2py(diff_table)\n",
    "            # Run inside captured context\n",
    "            return ctx.run(_read)\n",
    "\n",
    "\n",
    "    # Choose the correct file paths\n",
    "    if which_os == \"linux\":\n",
    "\n",
    "        readRDS = ro.r['readRDS']\n",
    "        df_RCC = readRDS(\"/home/larissa/Documents/Masterarbeit/RCC_results/crosstalker/no_subset_glom_removed/LR_data_final.Rds\")\n",
    "        df_MF = readRDS(\"/home/larissa/Documents/Masterarbeit/MF_results/crosstalker/all_celltypes/pval0_05/LR_data_final.Rds\")\n",
    "\n",
    "        \n",
    "        tables_RCC = df_RCC.slots[\"tables\"]\n",
    "        diff_table_RCC = tables_RCC[2]\n",
    "        RCC_diff_df = pandas2ri.rpy2py(diff_table_RCC)\n",
    "\n",
    "        tables_MF = df_MF.slots[\"tables\"]\n",
    "        diff_table_MF = tables_MF[2]\n",
    "        MF_diff_df = pandas2ri.rpy2py(diff_table_MF)\n",
    "\n",
    "    elif which_os == \"windows\":\n",
    "        readRDS = ro.r['readRDS']\n",
    "        df_RCC = readRDS(\"/home/larissa/Documents/Masterarbeit/RCC_results/crosstalker/no_subset_glom_removed/LR_data_final.Rds\")\n",
    "        df_MF = readRDS(\"/home/larissa/Documents/Masterarbeit/MF_results/crosstalker/all_celltypes/pval0_05/LR_data_final.Rds\")\n",
    "\n",
    "        \n",
    "\n",
    "        tables_RCC = df_RCC.slots[\"tables\"]\n",
    "        diff_table_RCC = tables_RCC[2]\n",
    "        RCC_diff_df = pandas2ri.rpy2py(diff_table_RCC)\n",
    "\n",
    "        tables_MF = df_MF.slots[\"tables\"]\n",
    "\n",
    "        diff_table_MF = tables_MF[2]\n",
    "        MF_diff_df = pandas2ri.rpy2py(diff_table_MF)\n",
    "\n",
    "    elif which_os == \"windows11\":\n",
    "        df_RCC = \"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\RCC_results\\\\crosstalker\\\\final_filtering\\\\LR_data_final.Rds\"\n",
    "        df_MF = \"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\MF_results\\\\crosstalker\\\\final_filtering\\\\LR_data_final.Rds\"\n",
    "\n",
    "\n",
    "        RCC_diff_df = load_diff_table(df_RCC)\n",
    "        MF_diff_df = load_diff_table(df_MF)\n",
    "\n",
    "\n",
    "    RCC_diff_df[\"gene_A\"] = RCC_diff_df[\"gene_A\"].apply([lambda x: x.removesuffix(\"|L\")])\n",
    "    RCC_diff_df[\"gene_B\"] = RCC_diff_df[\"gene_B\"].apply([lambda x: x.removesuffix(\"|R\")])\n",
    "    RCC_diff_df[\"lr_pair\"] = RCC_diff_df[\"gene_A\"] + \"_\" + RCC_diff_df[\"gene_B\"]\n",
    "    RCC_diff_df = RCC_diff_df[(~RCC_diff_df[\"source\"].isin([\"Glomerular endothelium\", \"Podocytes\", \"OM Type A-ICs\", \"Type B-IC\",\"Type A-ICs\", \"TAL of LOH\"])) & (~RCC_diff_df[\"target\"].isin([\"Glomerular endothelium\", \"Podocytes\", \"OM Type A-ICs\", \"Type B-IC\", \"Type A-ICs\", \"TAL of LOH\"]))]\n",
    "\n",
    "    MF_diff_df[\"gene_A\"] = MF_diff_df[\"gene_A\"].apply([lambda x: x.removesuffix(\"|L\")])\n",
    "    MF_diff_df[\"gene_B\"] = MF_diff_df[\"gene_B\"].apply([lambda x: x.removesuffix(\"|R\")])\n",
    "    MF_diff_df[\"lr_pair\"] = MF_diff_df[\"gene_A\"] + \"_\" + MF_diff_df[\"gene_B\"]\n",
    "    MF_diff_df = MF_diff_df[(~MF_diff_df[\"source\"].isin([\"Fibroblasts\"])) & (~MF_diff_df[\"target\"].isin([\"Fibroblasts\"]))]\n",
    "\n",
    "    #if not big_df.empty:\n",
    "    #    interaction_genes_only = genes_only\n",
    "    #print(interaction_genes_only)\n",
    "    RCC_lrscores = pd.DataFrame()\n",
    "    MF_lrscores = pd.DataFrame()\n",
    "    RCC_df_list = []\n",
    "    MF_df_list  = []\n",
    "\n",
    "    for i in range(len(clusters_cleaned)):\n",
    "\n",
    "        RCC_diff_df_filtered = RCC_diff_df[RCC_diff_df[\"source\"].isin(clusters_cleaned[i]) | RCC_diff_df[\"target\"].isin(clusters_cleaned[i])]\n",
    "        MF_diff_df_filtered = MF_diff_df[MF_diff_df[\"source\"].isin(clusters_cleaned[i]) | MF_diff_df[\"target\"].isin(clusters_cleaned[i])]\n",
    "\n",
    "        if intra_inter == \"inter\":\n",
    "\n",
    "            if i in interaction_genes_only:\n",
    "                #print(\"interaction_genes\", interaction_genes_only)\n",
    "                print(i)\n",
    "                for gene in np.unique(interaction_genes_only[i]):\n",
    "                    print(gene)\n",
    "                    #RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"gene_B\"] == gene)| (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(RCC_diff_df_filtered_gene) > 0:\n",
    "                        RCC_df_list.append(RCC_diff_df_filtered_gene)\n",
    "                        RCC_lrscores = pd.concat((RCC_lrscores, RCC_diff_df_filtered_gene))\n",
    "\n",
    "                    #MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"gene_A\"] == gene) | (MF_diff_df_filtered[\"gene_B\"] == gene) | (MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(MF_diff_df_filtered_gene) > 0:\n",
    "                        MF_df_list.append(MF_diff_df_filtered_gene)\n",
    "                        MF_lrscores = pd.concat((MF_lrscores, MF_diff_df_filtered_gene))\n",
    "\n",
    "        elif intra_inter == \"intra\":\n",
    "           \n",
    "           if i in interaction_genes_only:\n",
    "                #print(\"interaction_genes\", interaction_genes_only)\n",
    "                print(i)\n",
    "                for gene in np.unique(interaction_genes_only[i]):\n",
    "                    print(gene)\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"gene_B\"] == gene)| (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    #RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(RCC_diff_df_filtered_gene) > 0:\n",
    "                        RCC_df_list.append(RCC_diff_df_filtered_gene)\n",
    "                        RCC_lrscores = pd.concat((RCC_lrscores, RCC_diff_df_filtered_gene))\n",
    "\n",
    "                    #MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"gene_A\"] == gene) | (MF_diff_df_filtered[\"gene_B\"] == gene) | (MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(MF_diff_df_filtered_gene) > 0:\n",
    "                        MF_df_list.append(MF_diff_df_filtered_gene)\n",
    "                        MF_lrscores = pd.concat((MF_lrscores, MF_diff_df_filtered_gene))\n",
    "\n",
    "\n",
    "    #print(\"df list\", RCC_df_list)\n",
    "\n",
    "    cluster_dict = {\n",
    "        k: [v.removeprefix(\"RCC_\").removeprefix(\"MF_\") for v in vals]\n",
    "        for k, vals in cluster_dict.items()\n",
    "    }\n",
    "    #mapping column to specified clusters\n",
    "    mapping = {\n",
    "        item: cluster\n",
    "        for cluster, items in cluster_dict.items()\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "    grouped_list_RCC = []\n",
    "    grouped_list_MF = []\n",
    "\n",
    "    for df in RCC_df_list:\n",
    "        df[\"cluster_t\"] = df[\"target\"].map(mapping)\n",
    "        df[\"cluster_s\"] = df[\"source\"].map(mapping)\n",
    "\n",
    "        grouped = df.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "        \"LRScore\": \"mean\"\n",
    "        #\"source\": \"first\",    # or \" \".join, list, etc.\n",
    "        #\"lr_pair\": \"first\"  # repeat for other cols\n",
    "        })\n",
    "        grouped_list_RCC.append(grouped)\n",
    "\n",
    "    #print(grouped_list_RCC)\n",
    "    final_df_RCC = pd.concat(grouped_list_RCC, ignore_index=True)\n",
    "\n",
    "    for df in MF_df_list:\n",
    "        df[\"cluster_t\"] = df[\"target\"].map(mapping)\n",
    "        df[\"cluster_s\"] = df[\"source\"].map(mapping)\n",
    "\n",
    "        #grouped = df.groupby(\"cluster\")[\"LRScore\"].mean().reset_index()\n",
    "        grouped = df.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "        \"LRScore\": \"mean\"\n",
    "        #\"source\": \"first\",    # or \" \".join, list, etc.\n",
    "        #\"lr_pair\": \"first\"  # repeat for other cols\n",
    "        })\n",
    "        grouped_list_MF.append(grouped)\n",
    "\n",
    "    final_df_MF = pd.concat(grouped_list_MF, ignore_index=True)\n",
    "\n",
    "    RCC_final = final_df_RCC.rename(columns={\"LRScore\": \"LRScore_RCC\"})\n",
    "    MF_final = final_df_MF.rename(columns={\"LRScore\": \"LRScore_MF\"})\n",
    "\n",
    "    merged = pd.merge(\n",
    "        RCC_final,\n",
    "        MF_final,\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"   # only keep common cluster-target combos\n",
    "    )\n",
    "\n",
    "\n",
    "    merged[\"direction_RCC\"] = merged[\"LRScore_RCC\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")\n",
    "    merged[\"direction_MF\"] = merged[\"LRScore_MF\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")\n",
    "\n",
    "    merged[\"same_direction\"] = merged[\"direction_RCC\"] == merged[\"direction_MF\"]\n",
    "\n",
    "    subsetmerged = merged[merged[\"same_direction\"] == True].drop_duplicates()\n",
    "\n",
    "    if intra_inter == \"intra\":\n",
    "                subsetmerged = subsetmerged[(subsetmerged[\"cluster_s\"] == subsetmerged[\"cluster_t\"])]\n",
    "\n",
    "    elif intra_inter == \"inter\":\n",
    "                subsetmerged = subsetmerged[(subsetmerged[\"cluster_s\"] != subsetmerged[\"cluster_t\"])]\n",
    "\n",
    "    trend = merged.groupby(\"lr_pair\").agg(\n",
    "        mean_RCC=(\"LRScore_RCC\", \"mean\"),\n",
    "        mean_MF=(\"LRScore_MF\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Derive trend directions from the mean\n",
    "    trend[\"trend_RCC\"] = trend[\"mean_RCC\"].apply(lambda x: \"pos\" if x > 0 else (\"neg\" if x < 0 else \"zero\"))\n",
    "    trend[\"trend_MF\"]  = trend[\"mean_MF\"].apply(lambda x: \"pos\" if x > 0 else (\"neg\" if x < 0 else \"zero\"))\n",
    "\n",
    "    # Check if directions match\n",
    "    trend[\"same_overall_trend\"] = trend[\"trend_RCC\"] == trend[\"trend_MF\"]\n",
    "    trend_true = trend[trend[\"same_overall_trend\"] == True]\n",
    "\n",
    "    #mapped which cell types belong to which clusters and if they're the source or target cell type\n",
    "    cluster_dict = {\n",
    "        k: [v.removeprefix(\"RCC_\").removeprefix(\"MF_\") for v in vals]\n",
    "        for k, vals in cluster_dict.items()\n",
    "    }\n",
    "\n",
    "    mapping = {\n",
    "        item: cluster\n",
    "        for cluster, items in cluster_dict.items()\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "    grouped_list_RCC = []\n",
    "    grouped_list_MF = []\n",
    "    # Apply to each dataframe in RCC_df_list\n",
    "\n",
    "    RCC_split = RCC_diff_df.copy()\n",
    "    RCC_split[\"cluster_t\"] = RCC_split[\"target\"].map(mapping)\n",
    "    RCC_split[\"cluster_s\"] = RCC_split[\"source\"].map(mapping)\n",
    "\n",
    "    MF_split = MF_diff_df.copy()\n",
    "    MF_split[\"cluster_t\"] = MF_split[\"target\"].map(mapping)\n",
    "    MF_split[\"cluster_s\"] = MF_split[\"source\"].map(mapping)\n",
    "\n",
    "\n",
    "    if intra_inter == \"intra\":\n",
    "    #            RCC_split = RCC_split[(RCC_split[\"cluster_s\"] == RCC_split[\"cluster_t\"])]\n",
    "    #            print(RCC_split)\n",
    "    #            MF_split = MF_split[(MF_split[\"cluster_s\"] == MF_split[\"cluster_t\"])]  \n",
    "    #\n",
    "                RCC_split = RCC_split[(RCC_split[\"source\"] != RCC_split[\"target\"])]\n",
    "                MF_split = MF_split[(MF_split[\"source\"] != MF_split[\"target\"])]  \n",
    "    #elif intra_inter == \"inter\":\n",
    "    #            RCC_split = RCC_split[(RCC_split[\"cluster_s\"] != RCC_split[\"cluster_t\"])]\n",
    "    #            MF_split = MF_split[(MF_split[\"cluster_s\"] != MF_split[\"cluster_t\"])]  \n",
    "                \n",
    "    subsetmerged_RCC = RCC_split.merge(\n",
    "        subsetmerged[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    subsetmerged_MF = MF_split.merge(\n",
    "        subsetmerged[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    subsetmerged_RCC['gene_A'] = subsetmerged_RCC['gene_A'].astype(str) + '|L'\n",
    "    subsetmerged_RCC['gene_B'] = subsetmerged_RCC['gene_B'].astype(str) + '|R'\n",
    "\n",
    "    subsetmerged_MF['gene_A'] = subsetmerged_MF['gene_A'].astype(str) + '|L'\n",
    "    subsetmerged_MF['gene_B'] = subsetmerged_MF['gene_B'].astype(str) + '|R'\n",
    "\n",
    "\n",
    "    if overview ==  \"yes\":\n",
    "        overview_RCC = subsetmerged_RCC\n",
    "        overview_RCC[\"source\"] = subsetmerged_RCC[\"cluster_s\"]\n",
    "        overview_RCC[\"target\"] = subsetmerged_RCC[\"cluster_t\"] \n",
    "\n",
    "        overview_MF = subsetmerged_MF\n",
    "        overview_MF[\"source\"] = subsetmerged_MF[\"cluster_s\"]\n",
    "        overview_MF[\"target\"] = subsetmerged_MF[\"cluster_t\"]      \n",
    "\n",
    "    #if experimental == \"yes\":\n",
    "                # Keep only Ligand-Receptor edges\n",
    "    #            lrobj_tbl = subsetmerged_RCC\n",
    "                # Incoming: source  ligand  receptor  target\n",
    "    #            incoming = lrobj_tbl[['source', 'gene_A', 'gene_B', 'target', 'LRScore', \"cluster_t\"]].copy()\n",
    "\n",
    "                # Outgoing: target  downstream ligand#\n",
    "    #            outgoing = lrobj_tbl[['source', 'gene_A', 'LRScore']].copy()\n",
    "    #            outgoing['downstream_l'] = outgoing['gene_A'] + \"|DL\"\n",
    "    #            outgoing.rename(columns={'source': 'target', 'LRScore': 'LRScore_down'}, inplace=True)\n",
    "\n",
    "                # Merge incoming with outgoing once\n",
    "    #            merged_lr = incoming.merge(\n",
    "    #                outgoing[['target', 'downstream_l', 'LRScore_down']],\n",
    "    #                on='target',\n",
    "    #                how='left'\n",
    "    #            )\n",
    "\n",
    "    for name, i in cluster_dict.items():\n",
    "        #print(subset_RCC)\n",
    "        #subsetmerged_RCC = subsetmerged_RCC[subsetmerged_RCC[\"lr_pair\"].isin(interaction_genes_only[i])] \n",
    "        subsetmerged_RCC_s = subsetmerged_RCC[subsetmerged_RCC[\"source\"].isin(i)] \n",
    "        subsetmerged_RCC_t = subsetmerged_RCC[subsetmerged_RCC[\"target\"].isin(i)]\n",
    "\n",
    "        #subsetmerged_MF = subsetmerged_MF[subsetmerged_MF[\"lr_pair\"].isin(interaction_genes_only[i])] \n",
    "        subsetmerged_MF_s = subsetmerged_MF[subsetmerged_MF[\"source\"].isin(i)]\n",
    "        subsetmerged_MF_t = subsetmerged_MF[subsetmerged_MF[\"target\"].isin(i)]\n",
    "\n",
    "        if overview == \"yes\":\n",
    "            \n",
    "            subsetmerged_RCC_s = overview_RCC[overview_RCC[\"source\"] == name] \n",
    "            subsetmerged_RCC_t = overview_RCC[overview_RCC[\"target\"] == name]\n",
    "        \n",
    "            subsetmerged_MF_s = overview_MF[overview_MF[\"source\"] == name]\n",
    "            subsetmerged_MF_t = overview_MF[overview_MF[\"target\"] == name]\n",
    "             \n",
    "\n",
    "\n",
    "        if intra_inter == \"intra\":\n",
    "            print(name)\n",
    "            print(\"RCC\")\n",
    "            pycrosstalker.pl.plot_sankey(subsetmerged_RCC_s,threshold = 50, plt_name = None)\n",
    "            print(\"MF\")\n",
    "            pycrosstalker.pl.plot_sankey(subsetmerged_MF_s, threshold=50, plt_name =None)\n",
    "\n",
    "        elif intra_inter == \"inter\":\n",
    "            if experimental == \"yes\":\n",
    "       \n",
    "                #df_cluster = merged_lr[merged_lr['cluster_t'] == name]\n",
    "                print(name)\n",
    "                print(\"RCC\")\n",
    "                plot_sankey(subsetmerged_RCC, target_cluster = name, threshold =50, plt_name = None)\n",
    "                #plot_sankey(subsetmerged_RCC_t,threshold = 100, plt_name = f\"RCC  {name}\")\n",
    "                #print(\"MF\")\n",
    "                #plot_sankey(subsetmerged_MF_s, threshold=100, plt_name = f\"MF {name}\")\n",
    "                #plot_sankey(subsetmerged_MF_t, threshold=100, plt_name = f\"MF {name}\")\n",
    "            else:\n",
    "                print(name)\n",
    "                print(\"RCC\")\n",
    "                plot_sankey_half(subsetmerged_RCC_s, threshold =50, plt_name = None)\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_RCC_t,threshold = 50, plt_name =None)\n",
    "                print(\"MF\")\n",
    "                plot_sankey_half(subsetmerged_MF_s, threshold=50, plt_name = None)\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_MF_t, threshold=50, plt_name =None)\n",
    "\n",
    "\n",
    "    return subsetmerged, subsetmerged_RCC, subsetmerged_MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_mf_sankeys(f, clusters_cleaned, df_full, top_terms_list_MF, intra_inter, which_os = \"linux\", cluster_dict = cluster_dict, overview = None, experimental = None):    \n",
    "\n",
    "    def flatten(xss):\n",
    "        return [x for xs in xss for x in xs]\n",
    "    \n",
    "    all_interactions = f\n",
    "    clusters = list(cluster_dict.values())\n",
    "    df_full_mf = df_full[df_full[\"Namespace\"] == \"MF\"]\n",
    "    df_full_mf = df_full_mf[[\"Gene\", \"GOName\"]]\n",
    "    #print(df_full_mf)\n",
    "    #print(top_terms_list_MF)\n",
    "    #df_full_bp.pivot(index=\"GOName\", columns=\"Gene\")\n",
    "    genes_mfs = df_full_mf.groupby(\"GOName\")[\"Gene\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "    #get bp terms that only appear in one single cluster\n",
    "    unique_per_cluster = []\n",
    "\n",
    "    #the <2 not important here, just didnt delete bc i copied it from the unique genes function\n",
    "    for i, cluster in enumerate(top_terms_list_MF):\n",
    "        if len(clusters[i]) < 1:\n",
    "            #unique_per_cluster.append(set())\n",
    "            continue\n",
    "        set_i = set(cluster)  # interactions in this cluster\n",
    "        others = set().union(*[top_terms_list_MF[j]for j in range(len(top_terms_list_MF)) if j != i])\n",
    "        unique = set_i - others  # LRs only in this cluster\n",
    "        unique_per_cluster.append(unique)\n",
    "\n",
    "\n",
    "    for idx, uniq in enumerate(unique_per_cluster):\n",
    "        cluster_key = list(cluster_dict.keys())[idx]\n",
    "        print(f\"{cluster_key}: {uniq}\")\n",
    "\n",
    "    genes_mfs_sub = genes_mfs[genes_mfs.index.isin(flatten(unique_per_cluster))]\n",
    "\n",
    "\n",
    "    #doesnt check if lr pair is in cluster if using methods 1c where genes are already split\n",
    "    #knnen einfach einzeln da sein\n",
    "    method= \"d\"\n",
    "\n",
    "    interactions_in_mf = {}\n",
    "    interaction_genes_only_mf = {}\n",
    "\n",
    "\n",
    "    for i, lr_sets in enumerate(all_interactions):\n",
    "        if not (lr_sets):\n",
    "            continue\n",
    "        cluster_hits = []\n",
    "        interaction_genes = []\n",
    "        #print(unique_per_cluster[i])\n",
    "        for j in unique_per_cluster[i]:\n",
    "            \n",
    "            mfs_of_interest = [j]\n",
    "\n",
    "            #print(bps_of_interest)\n",
    "            genes_mfs_sub = genes_mfs[genes_mfs.index.isin(mfs_of_interest)]\n",
    "            #print(genes_bps_sub)\n",
    "            \n",
    "            \n",
    "            for interaction in lr_sets:\n",
    "                # split lr into ligand and receptor\n",
    "                if \"_\" in interaction:\n",
    "                    genes = interaction.split(\"_\")\n",
    "                else:\n",
    "                    genes = [interaction]\n",
    "                #print(genes)\n",
    "                for mf, genes_in_mf in genes_mfs_sub.items():\n",
    "                    if not isinstance(genes_in_mf, set):\n",
    "                        genes_in_mf = set(genes_in_mf)\n",
    "\n",
    "                    #print(genes_in_bp)\n",
    "                    # are both l and r in this biological process\n",
    "                    matching = [g for g in genes if g in genes_in_mf]\n",
    "                    #matching = [(g, \"ligand\" if idx==0 else \"receptor\") \n",
    "                    #     for idx, g in enumerate(genes) if g in genes_in_bp]\n",
    "                    #print(matching)\n",
    "                    # if both ligand and receptor are in this BP then keep\n",
    "                    if method == \"d\":\n",
    "                        if len(matching) >= 1:  \n",
    "                            cluster_hits.append((clusters[i], interaction, mf, matching))\n",
    "                            interaction_genes.append(interaction)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        if len(matching) >= 2:  \n",
    "                            cluster_hits.append((clusters[i], interaction, mf, matching))\n",
    "                            interaction_genes.append(interaction)\n",
    "\n",
    "        interactions_in_mf[i] = cluster_hits\n",
    "        interaction_genes_only_mf[i] = interaction_genes\n",
    "\n",
    "        \n",
    "    print(\"inter action genes\", interaction_genes_only_mf)\n",
    "    for i, val in interaction_genes_only_mf.items():\n",
    "        print(len(set(val)))\n",
    "\n",
    "    import contextvars\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects import pandas2ri, default_converter\n",
    "    from rpy2.robjects.conversion import localconverter, set_conversion\n",
    "\n",
    "    if which_os == \"windows11\":\n",
    "        # Initialize rpy2 conversion system\n",
    "        set_conversion(default_converter)\n",
    "\n",
    "        # Copy current context to propagate conversion settings into threads\n",
    "        ctx = contextvars.copy_context()\n",
    "\n",
    "        def load_diff_table(path: str):\n",
    "            def _read():\n",
    "                readRDS = ro.r['readRDS']\n",
    "                df = readRDS(path)\n",
    "                tables = df.slots['tables']\n",
    "                diff_table = tables[2]\n",
    "                with localconverter(default_converter + pandas2ri.converter):\n",
    "                    return ro.conversion.rpy2py(diff_table)\n",
    "            # Run inside captured context\n",
    "            return ctx.run(_read)\n",
    "\n",
    "\n",
    "    # Choose the correct file paths\n",
    "    if which_os == \"linux\":\n",
    "\n",
    "        readRDS = ro.r['readRDS']\n",
    "        df_RCC = readRDS(\"/home/larissa/Documents/Masterarbeit/RCC_results/crosstalker/no_subset_glom_removed/LR_data_final.Rds\")\n",
    "        df_MF = readRDS(\"/home/larissa/Documents/Masterarbeit/MF_results/crosstalker/all_celltypes/pval0_05/LR_data_final.Rds\")\n",
    "\n",
    "        \n",
    "        tables_RCC = df_RCC.slots[\"tables\"]\n",
    "        diff_table_RCC = tables_RCC[2]\n",
    "        RCC_diff_df = pandas2ri.rpy2py(diff_table_RCC)\n",
    "\n",
    "        tables_MF = df_MF.slots[\"tables\"]\n",
    "        diff_table_MF = tables_MF[2]\n",
    "        MF_diff_df = pandas2ri.rpy2py(diff_table_MF)\n",
    "\n",
    "    elif which_os == \"windows\":\n",
    "        readRDS = ro.r['readRDS']\n",
    "        df_RCC = readRDS(\"/home/larissa/Documents/Masterarbeit/RCC_results/crosstalker/no_subset_glom_removed/LR_data_final.Rds\")\n",
    "        df_MF = readRDS(\"/home/larissa/Documents/Masterarbeit/MF_results/crosstalker/all_celltypes/pval0_05/LR_data_final.Rds\")\n",
    "\n",
    "        \n",
    "\n",
    "        tables_RCC = df_RCC.slots[\"tables\"]\n",
    "        diff_table_RCC = tables_RCC[2]\n",
    "        RCC_diff_df = pandas2ri.rpy2py(diff_table_RCC)\n",
    "\n",
    "        tables_MF = df_MF.slots[\"tables\"]\n",
    "        diff_table_MF = tables_MF[2]\n",
    "        MF_diff_df = pandas2ri.rpy2py(diff_table_MF)\n",
    "\n",
    "    elif which_os == \"windows11\":\n",
    "        df_RCC = \"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\RCC_results\\\\crosstalker\\\\final_filtering\\\\LR_data_final.Rds\"\n",
    "        df_MF = \"C:\\\\Users\\\\laris\\\\Documents\\\\Studium\\\\Masterarbeit\\\\MF_results\\\\crosstalker\\\\final_filtering\\\\LR_data_final.Rds\"\n",
    "\n",
    "        RCC_diff_df = load_diff_table(df_RCC)\n",
    "        MF_diff_df = load_diff_table(df_MF)\n",
    "\n",
    "\n",
    "    RCC_diff_df[\"gene_A\"] = RCC_diff_df[\"gene_A\"].apply([lambda x: x.removesuffix(\"|L\")])\n",
    "    RCC_diff_df[\"gene_B\"] = RCC_diff_df[\"gene_B\"].apply([lambda x: x.removesuffix(\"|R\")])\n",
    "    RCC_diff_df[\"lr_pair\"] = RCC_diff_df[\"gene_A\"] + \"_\" + RCC_diff_df[\"gene_B\"]\n",
    "    RCC_diff_df = RCC_diff_df[(~RCC_diff_df[\"source\"].isin([\"Glomerular endothelium\", \"Podocytes\", \"OM Type A-ICs\", \"Type B-IC\",\"Type A-ICs\", \"TAL of LOH\"])) & (~RCC_diff_df[\"target\"].isin([\"Glomerular endothelium\", \"Podocytes\", \"OM Type A-ICs\", \"Type B-IC\", \"Type A-ICs\", \"TAL of LOH\"]))]\n",
    "\n",
    "    MF_diff_df[\"gene_A\"] = MF_diff_df[\"gene_A\"].apply([lambda x: x.removesuffix(\"|L\")])\n",
    "    MF_diff_df[\"gene_B\"] = MF_diff_df[\"gene_B\"].apply([lambda x: x.removesuffix(\"|R\")])\n",
    "    MF_diff_df[\"lr_pair\"] = MF_diff_df[\"gene_A\"] + \"_\" + MF_diff_df[\"gene_B\"]\n",
    "    MF_diff_df = MF_diff_df[(~MF_diff_df[\"source\"].isin([\"Fibroblasts\"])) & (~MF_diff_df[\"target\"].isin([\"Fibroblasts\"]))]\n",
    "\n",
    "    #if not big_df.empty:\n",
    "    #    interaction_genes_only = genes_only\n",
    "    #print(interaction_genes_only)\n",
    "    RCC_lrscores = pd.DataFrame()\n",
    "    MF_lrscores = pd.DataFrame()\n",
    "    RCC_df_list = []\n",
    "    MF_df_list  = []\n",
    "\n",
    "    for i in range(len(clusters_cleaned)):\n",
    "\n",
    "        RCC_diff_df_filtered = RCC_diff_df[RCC_diff_df[\"source\"].isin(clusters_cleaned[i]) | RCC_diff_df[\"target\"].isin(clusters_cleaned[i])]\n",
    "        MF_diff_df_filtered = MF_diff_df[MF_diff_df[\"source\"].isin(clusters_cleaned[i]) | MF_diff_df[\"target\"].isin(clusters_cleaned[i])]\n",
    "\n",
    "        if intra_inter == \"inter\":\n",
    "\n",
    "            if i in interaction_genes_only_mf:\n",
    "                print(\"interaction_genes\", interaction_genes_only_mf)\n",
    "                print(i)\n",
    "                for gene in np.unique(interaction_genes_only_mf[i]):\n",
    "                    print(gene)\n",
    "                    f = clusters_cleaned.iloc(i)\n",
    "                    #RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"gene_B\"] == gene)| (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(RCC_diff_df_filtered_gene) > 0:\n",
    "                        RCC_df_list.append(RCC_diff_df_filtered_gene)\n",
    "                        RCC_lrscores = pd.concat((RCC_lrscores, RCC_diff_df_filtered_gene))\n",
    "\n",
    "                    #MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"gene_A\"] == gene) | (MF_diff_df_filtered[\"gene_B\"] == gene) | (MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(MF_diff_df_filtered_gene) > 0:\n",
    "                        MF_df_list.append(MF_diff_df_filtered_gene)\n",
    "                        MF_lrscores = pd.concat((MF_lrscores, MF_diff_df_filtered_gene))\n",
    "        elif intra_inter == \"intra\":\n",
    "           \n",
    "           if i in interaction_genes_only_mf:\n",
    "                print(\"interaction_genes\", interaction_genes_only_mf)\n",
    "                print(i)\n",
    "                for gene in np.unique(interaction_genes_only_mf[i]):\n",
    "                    print(gene)\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"gene_A\"] == gene) | (RCC_diff_df_filtered[\"gene_B\"] == gene)| (RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    #RCC_diff_df_filtered_gene = RCC_diff_df_filtered[(RCC_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    RCC_diff_df_filtered_gene = RCC_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(RCC_diff_df_filtered_gene) > 0:\n",
    "                        RCC_df_list.append(RCC_diff_df_filtered_gene)\n",
    "                        RCC_lrscores = pd.concat((RCC_lrscores, RCC_diff_df_filtered_gene))\n",
    "\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"gene_A\"] == gene) | (MF_diff_df_filtered[\"gene_B\"] == gene) | (MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    #MF_diff_df_filtered_gene = MF_diff_df_filtered[(MF_diff_df_filtered[\"lr_pair\"] == gene)]\n",
    "                    MF_diff_df_filtered_gene = MF_diff_df_filtered_gene.sort_values(\"LRScore\", ascending=False)\n",
    "                    if len(MF_diff_df_filtered_gene) > 0:\n",
    "                        MF_df_list.append(MF_diff_df_filtered_gene)\n",
    "                        MF_lrscores = pd.concat((MF_lrscores, MF_diff_df_filtered_gene))\n",
    "\n",
    "    cluster_dict = {\n",
    "        k: [v.removeprefix(\"RCC_\").removeprefix(\"MF_\") for v in vals]\n",
    "        for k, vals in cluster_dict.items()\n",
    "    }\n",
    "    #mapping column to specified clusters\n",
    "    mapping = {\n",
    "        item: cluster\n",
    "        for cluster, items in cluster_dict.items()\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "    grouped_list_RCC = []\n",
    "    grouped_list_MF = []\n",
    "\n",
    "    for df in RCC_df_list:\n",
    "\n",
    "        df[\"cluster_t\"] = df[\"target\"].map(mapping)\n",
    "        df[\"cluster_s\"] = df[\"source\"].map(mapping)\n",
    "\n",
    "        grouped = df.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "        \"LRScore\": \"mean\"\n",
    "        #\"source\": \"first\",    # or \" \".join, list, etc.\n",
    "        #\"lr_pair\": \"first\"  # repeat for other cols\n",
    "        })\n",
    "        grouped_list_RCC.append(grouped)\n",
    "\n",
    "    #print(grouped_list_RCC)\n",
    "    final_df_RCC = pd.concat(grouped_list_RCC, ignore_index=True)\n",
    "\n",
    "    for df in MF_df_list:\n",
    "        df[\"cluster_t\"] = df[\"target\"].map(mapping)\n",
    "        df[\"cluster_s\"] = df[\"source\"].map(mapping)\n",
    "\n",
    "        #grouped = df.groupby(\"cluster\")[\"LRScore\"].mean().reset_index()\n",
    "        grouped = df.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "        \"LRScore\": \"mean\"\n",
    "        #\"source\": \"first\",    # or \" \".join, list, etc.\n",
    "        #\"lr_pair\": \"first\"  # repeat for other cols\n",
    "        })\n",
    "        grouped_list_MF.append(grouped)\n",
    "\n",
    "    final_df_MF = pd.concat(grouped_list_MF, ignore_index=True)\n",
    "\n",
    "    RCC_final = final_df_RCC.rename(columns={\"LRScore\": \"LRScore_RCC\"})\n",
    "    MF_final = final_df_MF.rename(columns={\"LRScore\": \"LRScore_MF\"})\n",
    "\n",
    "    merged = pd.merge(\n",
    "        RCC_final,\n",
    "        MF_final,\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"   # only keep common cluster-target combos\n",
    "    )\n",
    "\n",
    "\n",
    "    merged[\"direction_RCC\"] = merged[\"LRScore_RCC\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")\n",
    "    merged[\"direction_MF\"] = merged[\"LRScore_MF\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")\n",
    "\n",
    "    merged[\"same_direction\"] = merged[\"direction_RCC\"] == merged[\"direction_MF\"]\n",
    "\n",
    "    subsetmerged = merged[merged[\"same_direction\"] == True].drop_duplicates()\n",
    "\n",
    "    if intra_inter == \"intra\":\n",
    "                subsetmerged = subsetmerged[(subsetmerged[\"cluster_s\"] == subsetmerged[\"cluster_t\"])]\n",
    "\n",
    "    elif intra_inter == \"inter\":\n",
    "                subsetmerged = subsetmerged[(subsetmerged[\"cluster_s\"] != subsetmerged[\"cluster_t\"])]\n",
    "\n",
    "    trend = merged.groupby(\"lr_pair\").agg(\n",
    "        mean_RCC=(\"LRScore_RCC\", \"mean\"),\n",
    "        mean_MF=(\"LRScore_MF\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Derive trend directions from the mean\n",
    "    trend[\"trend_RCC\"] = trend[\"mean_RCC\"].apply(lambda x: \"pos\" if x > 0 else (\"neg\" if x < 0 else \"zero\"))\n",
    "    trend[\"trend_MF\"]  = trend[\"mean_MF\"].apply(lambda x: \"pos\" if x > 0 else (\"neg\" if x < 0 else \"zero\"))\n",
    "\n",
    "    # Check if directions match\n",
    "    trend[\"same_overall_trend\"] = trend[\"trend_RCC\"] == trend[\"trend_MF\"]\n",
    "    trend_true = trend[trend[\"same_overall_trend\"] == True]\n",
    "\n",
    "    #mapped which cell types belong to which clusters and if they're the source or target cell type\n",
    "    cluster_dict = {\n",
    "        k: [v.removeprefix(\"RCC_\").removeprefix(\"MF_\") for v in vals]\n",
    "        for k, vals in cluster_dict.items()\n",
    "    }\n",
    "\n",
    "    mapping = {\n",
    "        item: cluster\n",
    "        for cluster, items in cluster_dict.items()\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "    grouped_list_RCC = []\n",
    "    grouped_list_MF = []\n",
    "    # Apply to each dataframe in RCC_df_list\n",
    "\n",
    "    RCC_split = RCC_diff_df.copy()\n",
    "    RCC_split[\"cluster_t\"] = RCC_split[\"target\"].map(mapping)\n",
    "    RCC_split[\"cluster_s\"] = RCC_split[\"source\"].map(mapping)\n",
    "\n",
    "    MF_split = MF_diff_df.copy()\n",
    "    MF_split[\"cluster_t\"] = MF_split[\"target\"].map(mapping)\n",
    "    MF_split[\"cluster_s\"] = MF_split[\"source\"].map(mapping)\n",
    "\n",
    "\n",
    "    if intra_inter == \"intra\":\n",
    "    #            RCC_split = RCC_split[(RCC_split[\"cluster_s\"] == RCC_split[\"cluster_t\"])]\n",
    "    #            print(RCC_split)\n",
    "    #            MF_split = MF_split[(MF_split[\"cluster_s\"] == MF_split[\"cluster_t\"])]  \n",
    "    #\n",
    "                RCC_split = RCC_split[(RCC_split[\"source\"] != RCC_split[\"target\"])]\n",
    "                MF_split = MF_split[(MF_split[\"source\"] != MF_split[\"target\"])]  \n",
    "    #elif intra_inter == \"inter\":\n",
    "    #            RCC_split = RCC_split[(RCC_split[\"cluster_s\"] != RCC_split[\"cluster_t\"])]\n",
    "    #            MF_split = MF_split[(MF_split[\"cluster_s\"] != MF_split[\"cluster_t\"])]  \n",
    "                \n",
    "    subsetmerged_RCC = RCC_split.merge(\n",
    "        subsetmerged[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    subsetmerged_MF = MF_split.merge(\n",
    "        subsetmerged[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "        on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    subsetmerged_RCC['gene_A'] = subsetmerged_RCC['gene_A'].astype(str) + '|L'\n",
    "    subsetmerged_RCC['gene_B'] = subsetmerged_RCC['gene_B'].astype(str) + '|R'\n",
    "\n",
    "    subsetmerged_MF['gene_A'] = subsetmerged_MF['gene_A'].astype(str) + '|L'\n",
    "    subsetmerged_MF['gene_B'] = subsetmerged_MF['gene_B'].astype(str) + '|R'\n",
    "\n",
    "\n",
    "    if overview ==  \"yes\":\n",
    "        overview_RCC = subsetmerged_RCC\n",
    "        overview_RCC[\"source\"] = subsetmerged_RCC[\"cluster_s\"]\n",
    "        overview_RCC[\"target\"] = subsetmerged_RCC[\"cluster_t\"] \n",
    "\n",
    "        overview_MF = subsetmerged_MF\n",
    "        overview_MF[\"source\"] = subsetmerged_MF[\"cluster_s\"]\n",
    "        overview_MF[\"target\"] = subsetmerged_MF[\"cluster_t\"]      \n",
    "\n",
    "    #if experimental == \"yes\":\n",
    "                # Keep only Ligand-Receptor edges\n",
    "    #            lrobj_tbl = subsetmerged_RCC\n",
    "                # Incoming: source  ligand  receptor  target\n",
    "    #            incoming = lrobj_tbl[['source', 'gene_A', 'gene_B', 'target', 'LRScore', \"cluster_t\"]].copy()\n",
    "\n",
    "                # Outgoing: target  downstream ligand#\n",
    "    #            outgoing = lrobj_tbl[['source', 'gene_A', 'LRScore']].copy()\n",
    "    #            outgoing['downstream_l'] = outgoing['gene_A'] + \"|DL\"\n",
    "    #            outgoing.rename(columns={'source': 'target', 'LRScore': 'LRScore_down'}, inplace=True)\n",
    "\n",
    "                # Merge incoming with outgoing once\n",
    "    #            merged_lr = incoming.merge(\n",
    "    #                outgoing[['target', 'downstream_l', 'LRScore_down']],\n",
    "    #                on='target',\n",
    "    #                how='left'\n",
    "    #            )\n",
    "\n",
    "    for name, i in cluster_dict.items():\n",
    "        #print(subset_RCC)\n",
    "        subsetmerged_RCC_s = subsetmerged_RCC[subsetmerged_RCC[\"source\"].isin(i)] \n",
    "        subsetmerged_RCC_t = subsetmerged_RCC[subsetmerged_RCC[\"target\"].isin(i)]\n",
    "\n",
    "        subsetmerged_MF_s = subsetmerged_MF[subsetmerged_MF[\"source\"].isin(i)]\n",
    "        subsetmerged_MF_t = subsetmerged_MF[subsetmerged_MF[\"target\"].isin(i)]\n",
    "\n",
    "        if overview == \"yes\":\n",
    "            \n",
    "            subsetmerged_RCC_s = overview_RCC[overview_RCC[\"source\"] == name] \n",
    "            subsetmerged_RCC_t = overview_RCC[overview_RCC[\"target\"] == name]\n",
    "        \n",
    "            subsetmerged_MF_s = overview_MF[overview_MF[\"source\"] == name]\n",
    "            subsetmerged_MF_t = overview_MF[overview_MF[\"target\"] == name]\n",
    "             \n",
    "\n",
    "\n",
    "        if intra_inter == \"intra\":\n",
    "            print(\"RCC\")\n",
    "            pycrosstalker.pl.plot_sankey(subsetmerged_RCC_s,threshold = 100, plt_name =None)\n",
    "            print(\"MF\")\n",
    "            pycrosstalker.pl.plot_sankey(subsetmerged_MF_s, threshold=100, plt_name = None)\n",
    "\n",
    "        elif intra_inter == \"inter\":\n",
    "            if experimental == \"yes\":\n",
    "       \n",
    "                #df_cluster = merged_lr[merged_lr['cluster_t'] == name]\n",
    "                print(\"RCC\")\n",
    "                plot_sankey(subsetmerged_RCC, target_cluster = name, threshold =50, plt_name = None)\n",
    "                #plot_sankey(subsetmerged_RCC_t,threshold = 100, plt_name = f\"RCC  {name}\")\n",
    "                #print(\"MF\")\n",
    "                #plot_sankey(subsetmerged_MF_s, threshold=100, plt_name = f\"MF {name}\")\n",
    "                #plot_sankey(subsetmerged_MF_t, threshold=100, plt_name = f\"MF {name}\")\n",
    "            else:\n",
    "                print(\"RCC\")\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_RCC_s, threshold =50, plt_name =None)\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_RCC_t,threshold = 50, plt_name = None)\n",
    "                print(\"MF\")\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_MF_s, threshold=50, plt_name = None)\n",
    "                pycrosstalker.pl.plot_sankey(subsetmerged_MF_t, threshold=50, plt_name =None)\n",
    "\n",
    "\n",
    "    return subsetmerged, subsetmerged_RCC, subsetmerged_MF   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GO_stuff(opt, opt2, opt3, which_os = \"linux\", overview = None, experimental = None):\n",
    "    f, clusters_cleaned = get_intra_inter(opt = opt, opt2= opt2, opt3= opt3)\n",
    "    df_full, top_terms_list, top_terms_list_MF = plot_GO(f)\n",
    "    subsetmerged, subsetmerged_RCC, subsetmerged_MF = plot_unique_bp_sankeys(f, clusters_cleaned, df_full, top_terms_list, intra_inter = opt3, which_os = which_os, overview = overview,  experimental = experimental)\n",
    "    subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs = plot_unique_mf_sankeys(f, clusters_cleaned, df_full, top_terms_list_MF, intra_inter = opt3, which_os = which_os, overview = overview,  experimental = experimental)\n",
    " \n",
    "    return df_full, top_terms_list, subsetmerged, subsetmerged_RCC, subsetmerged_MF, subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_intra, top_terms_list_intra, subsetmerged_intra, subsetmerged_RCC_intra, subsetmerged_MF_intra, subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs = GO_stuff(opt = \"unique\", opt2=\"a\", opt3= \"intra\", which_os = which_os, overview  = \"False\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b98b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b825666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_inter, top_terms_list_inter, subsetmerged_inter, subsetmerged_RCC_inter, subsetmerged_MF_inter, subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs  = GO_stuff(opt=\"unique\", opt2=\"a2\", opt3= \"inter\", which_os = which_os, overview = \"no\", experimental = \"fuck off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_intra.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4879ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_inter, top_terms_list_inter, subsetmerged_inter, subsetmerged_RCC_inter, subsetmerged_MF_inter, subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs  = GO_stuff(opt=\"unique\", opt2=\"a2\", opt3= \"inter\", which_os = \"windows11\", overview = \"yes\", experimental = \"fuck off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4784ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c061c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_MF_inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3388009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview\n",
    "df_full_inter, top_terms_list_inter, subsetmerged_inter, subsetmerged_RCC_inter, subsetmerged_MF_inter, subsetmerged_gomfs, subsetmerged_RCC_gomfs, subsetmerged_MF_gomfs = GO_stuff(opt=\"unique\", opt2=\"a2\", opt3= \"inter\", which_os = which_os, overview = \"yes\", experimental = \"fuck off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb818577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental\n",
    "df_full_inter, top_terms_list_inter, subsetmerged_inter, subsetmerged_RCC_inter, subsetmerged_MF_inter = GO_stuff(opt=\"unique\", opt2=\"a2\", opt3= \"inter\", which_os = which_os, overview = False, experimental = \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147763a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from sankeyflow import Sankey\n",
    "\n",
    "def plot_sankey(df, plt_name=\"Sankey Plot\",\n",
    "                        cat_cols=['source','gene_A','gene_B','target','downstream_l'],\n",
    "                        value_col='LRScore',\n",
    "                        threshold=50):\n",
    "    \"\"\"\n",
    "    Plot Sankey for a pre-filtered dataframe of a single target cluster.\n",
    "    \"\"\"\n",
    "    # Drop rows with no target (shouldnt happen but safe)\n",
    "    df = df.dropna(subset=['target'])\n",
    "    df = df.nlargest(threshold, value_col)\n",
    "    # Build flows\n",
    "    flows = []\n",
    "    for i in range(len(cat_cols)-1):\n",
    "        pairs = df[[cat_cols[i], cat_cols[i+1], value_col]].dropna()\n",
    "        for _, row in pairs.iterrows():\n",
    "            flows.append((row[cat_cols[i]], row[cat_cols[i+1]], row[value_col], {}))\n",
    "\n",
    "    if not flows:\n",
    "        print(\"No valid flows for Sankey.\")\n",
    "        return\n",
    "\n",
    "    # Color normalization\n",
    "    vmin, vmax = df[value_col].min(), df[value_col].max()\n",
    "    limit = max(abs(vmin), abs(vmax))\n",
    "    cmap = cm.get_cmap('RdBu_r')\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-limit, vcenter=0, vmax=limit)\n",
    "\n",
    "    # Apply colors to flows\n",
    "    for i, (s, t, v, meta) in enumerate(flows):\n",
    "        meta['color'] = mcolors.to_hex(cmap(norm(v)))\n",
    "        meta['alpha'] = 0.5\n",
    "        flows[i] = (s, t, 1, meta)  # uniform thickness\n",
    "\n",
    "    # Infer nodes for proper layout\n",
    "    nodes = Sankey.infer_nodes(flows)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    s = Sankey(\n",
    "        flows=flows,\n",
    "        nodes=nodes,\n",
    "        flow_color_mode_alpha=0.3,\n",
    "        node_opts=dict(label_format='{label}', label_pos='center')\n",
    "    )\n",
    "    s.draw(ax=ax)\n",
    "\n",
    "    # Colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', pad=0.02, shrink=0.6)\n",
    "    cbar.set_label(value_col, fontsize=12)\n",
    "\n",
    "    # Stage labels\n",
    "    stages = [\"Source\", \"Ligand\", \"Receptor\", \"Target\", \"Downstream L\"]\n",
    "    for i, stage in enumerate(stages):\n",
    "        ax.text(i*1.0, 1.02, stage, fontsize=10)\n",
    "\n",
    "    ax.set_title(plt_name, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sankey(lrobj_tbl, target=None, target_cluster=None,\n",
    "                      ligand_cluster=None, receptor_cluster=None,\n",
    "                      plt_name=None, threshold=50):\n",
    "    \"\"\"\n",
    "    Robust Sankey builder that ensures downstream ligand nodes appear.\n",
    "    Uses either 'cluster_t' or 'target' for cluster-level matching depending on what's present.\n",
    "    \"\"\"\n",
    "\n",
    "    def ensure_list(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        return [x] if isinstance(x, str) else x\n",
    "\n",
    "    target_cluster = ensure_list(target_cluster)\n",
    "    ligand_cluster = ensure_list(ligand_cluster)\n",
    "    receptor_cluster = ensure_list(receptor_cluster)\n",
    "\n",
    "    df = lrobj_tbl.copy()\n",
    "\n",
    "    # --- Decide which cluster column to use for cluster-level matching ---\n",
    "    if 'cluster_t' in df.columns:\n",
    "        cluster_col = 'cluster_t'\n",
    "    elif 'target' in df.columns and df['target'].str.contains(' ').any():\n",
    "        # prefer cluster_t if available, otherwise use target\n",
    "        cluster_col = 'target'\n",
    "    else:\n",
    "        cluster_col = 'target'\n",
    "\n",
    "    # Normalize cluster names for matching: compare a simplified form so \"Mast cells\" and \"Mast_cells\" match\n",
    "    def norm(x):\n",
    "        if pd.isna(x):\n",
    "            return x\n",
    "        return str(x).strip().lower().replace('_', ' ').replace('-', ' ')\n",
    "\n",
    "    df['_cluster_norm'] = df[cluster_col].map(norm)\n",
    "\n",
    "    # Normalize provided target_cluster list\n",
    "    if target_cluster is not None:\n",
    "        tgt_norm = [norm(x) for x in target_cluster]\n",
    "    else:\n",
    "        tgt_norm = None\n",
    "\n",
    "    # --- Incoming (to target cluster) and outgoing (from target cluster) selection ---\n",
    "    if tgt_norm is not None:\n",
    "        data_t = df[df['_cluster_norm'].isin(tgt_norm)].copy()   # interactions incoming to the target cluster (receptor = target)\n",
    "        data_s = df[df['_cluster_norm'].isin(tgt_norm)].copy()   # interactions where cluster == target cluster (we will use gene_A as downstream)\n",
    "    else:\n",
    "        # if no specific target cluster, use all\n",
    "        data_t = df.copy()\n",
    "        data_s = df.copy()\n",
    "\n",
    "    # Optional cluster filtering for source/target fields if provided\n",
    "    if ligand_cluster is not None:\n",
    "        lc_norm = [norm(x) for x in ligand_cluster]\n",
    "        # assume ligand cluster corresponds to the 'source' cluster column if present, else try to filter on source text\n",
    "        if 'source' in df.columns:\n",
    "            data_t = data_t[data_t['source'].map(norm).isin(lc_norm)]\n",
    "    if receptor_cluster is not None:\n",
    "        rc_norm = [norm(x) for x in receptor_cluster]\n",
    "        # assume receptor cluster corresponds to cluster_col (target)\n",
    "        data_t = data_t[data_t['_cluster_norm'].isin(rc_norm)]\n",
    "\n",
    "    # Limit to top-N by LRScore (do separately so we don't accidentally drop downstream mapping)\n",
    "    data_t = data_t.nlargest(min(threshold, len(data_t)), 'LRScore') if not data_t.empty else data_t\n",
    "    data_s = data_s.nlargest(min(threshold, len(data_s)), 'LRScore') if not data_s.empty else data_s\n",
    "\n",
    "    if data_t.empty:\n",
    "        print(\"No incoming interactions found (data_t is empty).\")\n",
    "    if data_s.empty:\n",
    "        print(\"No outgoing interactions found (data_s is empty).\")\n",
    "    if data_t.empty and data_s.empty:\n",
    "        return\n",
    "\n",
    "    # --- Build downstream ligand mapping ---\n",
    "    # Prefer using an existing downstream column if present (e.g. 'downstream_l' or 'downstream')\n",
    "    if 'downstream_l' in df.columns:\n",
    "        downstream_col = 'downstream_l'\n",
    "    elif 'downstream' in df.columns:\n",
    "        downstream_col = 'downstream'\n",
    "    else:\n",
    "        # fallback: use gene_A from rows where cluster==target cluster, append |DL\n",
    "        downstream_col = None\n",
    "\n",
    "    if downstream_col:\n",
    "        # use cluster_col -> downstream unique mapping\n",
    "        mapping = (data_s[[cluster_col, downstream_col]]\n",
    "                   .dropna(subset=[downstream_col])\n",
    "                   .groupby(cluster_col)[downstream_col]\n",
    "                   .unique()\n",
    "                   .to_dict())\n",
    "    else:\n",
    "        # create downstream from gene_A\n",
    "        tmp = data_s[[cluster_col, 'gene_A']].dropna(subset=['gene_A'])\n",
    "        tmp['downstream_l'] = tmp['gene_A'].astype(str) + \"|DL\"\n",
    "        mapping = tmp.groupby(cluster_col)['downstream_l'].unique().to_dict()\n",
    "\n",
    "    # Normalize keys in mapping for robust lookup\n",
    "    mapping_norm = {norm(k): v for k, v in mapping.items() if pd.notna(k)}\n",
    "\n",
    "    # Attach downstream_l to data_t by cluster (use normalized cluster)\n",
    "    data_t = data_t.copy()\n",
    "    data_t['_cluster_key'] = data_t[cluster_col].map(norm)\n",
    "    data_t['downstream_l'] = data_t['_cluster_key'].map(lambda k: mapping_norm.get(k, []))\n",
    "\n",
    "    # Expand rows with multiple downstream ligands (robust to NumPy arrays)\n",
    "    data_t['downstream_l'] = data_t['downstream_l'].apply(\n",
    "        lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray))\n",
    "        else ([x] if pd.notna(x) else [])\n",
    "    )\n",
    "    data_t = data_t.explode('downstream_l')\n",
    "    data_t['downstream_l'] = data_t['downstream_l'].replace('', np.nan)\n",
    "    # Expand rows with multiple downstream ligands\n",
    "    data_t = data_t.assign(downstream_l=data_t['downstream_l'].apply(lambda x: list(x) if (isinstance(x, (list, tuple)) or pd.notna(x)) else []))\n",
    "    data_t = data_t.explode('downstream_l')\n",
    "    # If empty string or nan, set to None so gen_sankey's dropna removes them\n",
    "    data_t['downstream_l'] = data_t['downstream_l'].replace('', np.nan)\n",
    "\n",
    "    # --- If downstream_l remains NaN for all rows, print diagnostics ---\n",
    "    n_down = data_t['downstream_l'].notna().sum()\n",
    "    print(f\"Found {n_down} non-null downstream ligand rows after expansion (out of {len(data_t)} rows).\")\n",
    "\n",
    "    # --- Build final dataframe for plotting ---\n",
    "    # We'll keep columns: source, gene_A (ligand), gene_B (receptor), cluster_col (target cluster label), downstream_l\n",
    "    plot_df = data_t.rename(columns={cluster_col: 'target_cluster'})[['source', 'gene_A', 'gene_B', 'target_cluster', 'downstream_l', 'LRScore']].copy()\n",
    "\n",
    "    # If no downstream entries, still include plot but warn\n",
    "    if plot_df['downstream_l'].isna().all():\n",
    "        print(\"Warning: no downstream ligands available to draw the last Sankey layer. Check mapping or ensure downstream column exists.\")\n",
    "    else:\n",
    "        print(\"Downstream ligand examples:\", plot_df['downstream_l'].dropna().unique()[:10])\n",
    "\n",
    "    # cat columns\n",
    "    cat_cols = ['source', 'gene_A', 'gene_B', 'target_cluster', 'downstream_l']\n",
    "    gen_sankey(plot_df, cat_cols, 'LRScore', title=plt_name or \"Sankey Plot (fixed)\")\n",
    "\n",
    "# --- Keep your existing gen_sankey function but ensure it accepts labels with spaces/characters ---\n",
    "# (If you changed gen_sankey earlier, the one you have should still work. If not, use your original.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b83d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.colors as pc\n",
    "import plotly.graph_objects as go\n",
    "from adjustText import adjust_text\n",
    "from gprofiler import GProfiler\n",
    "from sankeyflow import Sankey\n",
    "import json\n",
    "\n",
    "def plot_sankey(lrobj_tbl, target=None, target_cluster=None,\n",
    "                ligand_cluster=None, receptor_cluster=None,\n",
    "                plt_name=None, threshold=50):\n",
    "    \"\"\"\n",
    "    Sankey: source  ligand  receptor  target  downstream_ligand (|DL)\n",
    "    \"\"\"\n",
    "    print(lrobj_tbl)\n",
    "    # --- Helper to ensure inputs are list-like ---\n",
    "    def ensure_list(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        return [x] if isinstance(x, str) else x\n",
    "\n",
    "    target_cluster = ensure_list(target_cluster)\n",
    "    ligand_cluster = ensure_list(ligand_cluster)\n",
    "    receptor_cluster = ensure_list(receptor_cluster)\n",
    "\n",
    "    # --- Keep only LigandReceptor pairs ---\n",
    "\n",
    "    # --- Incoming to target cluster ---\n",
    "    data_t = lrobj_tbl[lrobj_tbl['target'].isin(target_cluster)].copy()\n",
    "\n",
    "    # --- Outgoing from target cluster ---\n",
    "    data_s = lrobj_tbl[lrobj_tbl['source'].isin(target_cluster)].copy()\n",
    "\n",
    "    # Optional cluster filtering\n",
    "    if ligand_cluster is not None:\n",
    "        data_t = data_t[data_t['source'].isin(ligand_cluster)]\n",
    "    if receptor_cluster is not None:\n",
    "        data_t = data_t[data_t['target'].isin(receptor_cluster)]\n",
    "\n",
    "    # Limit to top-N by LRScore\n",
    "    data_t = data_t.nlargest(min(threshold, len(data_t)), 'LRScore')\n",
    "    data_s = data_s.nlargest(min(threshold, len(data_s)), 'LRScore')\n",
    "\n",
    "    if data_t.empty and data_s.empty:\n",
    "        print(\"No valid interactions found.\")\n",
    "        return\n",
    "\n",
    "    # --- Map downstream ligands (with |DL suffix to separate layer) ---\n",
    "    # --- Prepare downstream ligands (vectorized) ---\n",
    "    data_s = data_s[['source', 'gene_A', 'LRScore']].copy()\n",
    "    data_s = data_s[data_s['source'].isin(receptor_cluster)]\n",
    "    data_s[\"LRScore\"] = 0\n",
    "    data_s['downstream_l'] = data_s['gene_A'] + \"|DL\"\n",
    "    data_s.rename(columns={'source': 'target'}, inplace=True)  # so we can merge on target\n",
    "\n",
    "    # Attach downstream ligands per target cluster\n",
    "    downstream_map = data_s.groupby('target')['downstream_l'].unique().to_dict()\n",
    "\n",
    "    df_expanded = data_t.copy()\n",
    "    df_expanded['downstream_l'] = df_expanded['target'].map(\n",
    "        lambda t: ','.join(downstream_map.get(t, []))\n",
    "    )\n",
    "    df_expanded = (\n",
    "        df_expanded\n",
    "        .assign(downstream_l=df_expanded['downstream_l'].str.split(','))\n",
    "        .explode('downstream_l')\n",
    "    )\n",
    "    # Merge with data_t to attach all downstream ligands\n",
    "    #df_expanded = data_t.merge(\n",
    "    #    data_s[['target', 'downstream_l']],\n",
    "    #    on='target',\n",
    "    #    how='left',\n",
    "    #    suffixes=('', '_down')\n",
    "    #)\n",
    "\n",
    "    #if data_t['downstream_l'].isna().all():\n",
    "    #    print(\"No downstream ligands found for target cluster.\")\n",
    "    #else:\n",
    "    #    n_found = data_t['downstream_l'].notna().sum()\n",
    "    #    print(f\"Downstream ligands added for {n_found} targets.\")\n",
    "\n",
    "    # --- Define columns and plot ---\n",
    "    cat_cols = ['source', 'gene_A', 'gene_B', 'target', 'downstream_l']\n",
    "    value_col = 'LRScore'  # for the main edges; use LRScore_down for downstream if desired\n",
    "    gen_sankey(df_expanded, cat_cols, value_col, title=plt_name or \"Sankey Plot\")\n",
    "\n",
    "\n",
    "def gen_sankey(df, cat_cols, value_col, title='Sankey Diagram'):\n",
    "    \"\"\"\n",
    "    Core Sankey generator using Sankey.infer_nodes()\n",
    "    \"\"\"\n",
    "\n",
    "    # Build flow list\n",
    "    flows = []\n",
    "    for i in range(len(cat_cols) - 1):\n",
    "        pairs = df[[cat_cols[i], cat_cols[i + 1], value_col]].dropna()\n",
    "        for _, row in pairs.iterrows():\n",
    "            flows.append((row[cat_cols[i]], row[cat_cols[i + 1]], row[value_col], {}))\n",
    "\n",
    "    if not flows:\n",
    "        print(\"No valid flows for Sankey.\")\n",
    "        return\n",
    "\n",
    "    # Normalize colors\n",
    "    vmin, vmax = df[value_col].min(), df[value_col].max()\n",
    "    limit = max(abs(vmin), abs(vmax))\n",
    "    cmap = cm.get_cmap('RdBu_r')\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-limit, vcenter=0, vmax=limit)\n",
    "\n",
    "    # Apply colors to flows\n",
    "    for i, (s, t, v, meta) in enumerate(flows):\n",
    "        meta['color'] = mcolors.to_hex(cmap(norm(v)))\n",
    "        meta['alpha'] = 0.5\n",
    "        flows[i] = (s, t, 1, meta)  # uniform flow width for readability\n",
    "\n",
    "    # --- Infer clean node layout ---\n",
    "    nodes = Sankey.infer_nodes(flows)\n",
    "    nodes_new = []\n",
    "    for level in nodes:\n",
    "        level_new = []\n",
    "        for node in level:\n",
    "            node_new = node + [{'color' : 'black',\n",
    "                                'label_pos':'center', 'label_opts': dict(fontsize=10, bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))}]\n",
    "            level_new.append(node_new)\n",
    "        nodes_new.append(level_new)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    s = Sankey(\n",
    "        flows=flows,\n",
    "        nodes=nodes_new,\n",
    "        flow_color_mode_alpha=0.3,\n",
    "        node_opts=dict(label_format='{label}'),\n",
    "    )\n",
    "    s.draw(ax=ax)\n",
    "\n",
    "    # --- Add colorbar ---\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', pad=0.01, shrink=0.5)\n",
    "    cbar.set_label(value_col, fontsize=12)\n",
    "\n",
    "    ax.text(x=-0.05, y=1.02, s=\"Source\", fontsize=10)\n",
    "    ax.text(x=0.95, y=1.02, s=\"Ligand\", fontsize=10)\n",
    "    ax.text(x=1.95, y=1.02, s=\"Receptor\", fontsize=10)\n",
    "    ax.text(x=2.95, y=1.02, s=\"Target\", fontsize=10)\n",
    "    ax.text(x=-3.95, y=1.02, s=\"Downstream L\", fontsize=10)\n",
    "  \n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD STUFF\n",
    "df_full_inter_tmp, top_terms_list_inter_tmp, subsetmerged_inter_tmp, subsetmerged_RCC_inter_tmp, subsetmerged_MF_inter_tmp = GO_stuff(opt = \"unique\", opt2=\"a2\", opt3= \"inter\", which_os = \"windows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45746b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_MF_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b325cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a998776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, i in zip(unique_per_cluster, unique_per_cluster_unique):\n",
    "    diff = (i - j).union(j - i)\n",
    "    same = i.intersection(j)\n",
    "    print(diff)\n",
    "    #print(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ce5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MF\n",
    "\n",
    "df_full_bp = df_full[df_full[\"Namespace\"] == \"MF\"]\n",
    "df_full_bp = df_full_bp[[\"Gene\", \"GOName\"]]\n",
    "df_full_bp\n",
    "#df_full_bp.pivot(index=\"GOName\", columns=\"Gene\")\n",
    "genes_bps = df_full_bp.groupby(\"GOName\")[\"Gene\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "#get bp terms that only appear in one single cluster\n",
    "unique_per_cluster = []\n",
    "\n",
    "#the <2 not important here, just didnt delete bc i copied it from the unique genes function\n",
    "for i, cluster in enumerate(top_terms_list_MF):\n",
    "    if len(clusters[i]) < 2:\n",
    "        unique_per_cluster.append([])\n",
    "        continue\n",
    "    set_i = set(cluster)  # interactions in this cluster\n",
    "    others = set().union(*[top_terms_list_MF[j]for j in range(len(top_terms_list_MF)) if j != i])\n",
    "    unique = set_i - others  # LRs only in this cluster\n",
    "    unique_per_cluster.append(unique)\n",
    "\n",
    "for idx, uniq in enumerate(unique_per_cluster):\n",
    "    cluster_key = list(cluster_dict.keys())[idx]\n",
    "    print(f\"{cluster_key}: {uniq}\")\n",
    "    \n",
    "\n",
    "genes_bps_sub = genes_bps[genes_bps.index.isin(flatten(unique_per_cluster))]\n",
    "print(genes_bps_sub)\n",
    "\n",
    "#doesnt check if lr pair is in cluster if using methods 1c where genes are already split\n",
    "#knnen einfach einzeln da sein\n",
    "method= \"d\"\n",
    "\n",
    "interactions_in_bp = {}\n",
    "interaction_genes_only = {}\n",
    "\n",
    "\n",
    "for i, lr_sets in enumerate(all_interactions):\n",
    "    if not (lr_sets):\n",
    "        continue\n",
    "    cluster_hits = []\n",
    "    interaction_genes = []\n",
    "    #print(unique_per_cluster[i])\n",
    "    for j in unique_per_cluster[i]:\n",
    "        \n",
    "        bps_of_interest = [j]\n",
    "\n",
    "        #print(bps_of_interest)\n",
    "        genes_bps_sub = genes_bps[genes_bps.index.isin(bps_of_interest)]\n",
    "        #print(genes_bps_sub)\n",
    "        \n",
    "        \n",
    "        for interaction in lr_sets:\n",
    "            # split lr into ligand and receptor\n",
    "            if \"_\" in interaction:\n",
    "                genes = interaction.split(\"_\")\n",
    "            else:\n",
    "                genes = [interaction]\n",
    "            #print(genes)\n",
    "            for bp, genes_in_bp in genes_bps_sub.items():\n",
    "                if not isinstance(genes_in_bp, set):\n",
    "                    genes_in_bp = set(genes_in_bp)\n",
    "\n",
    "                #print(genes_in_bp)\n",
    "                # are both l and r in this biological process\n",
    "                matching = [g for g in genes if g in genes_in_bp]\n",
    "                #matching = [(g, \"ligand\" if idx==0 else \"receptor\") \n",
    "                #     for idx, g in enumerate(genes) if g in genes_in_bp]\n",
    "                #print(matching)\n",
    "                # if both ligand and receptor are in this BP then keep\n",
    "                if method == \"d\":\n",
    "                    if len(matching) >= 1:  \n",
    "                        cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                        interaction_genes.append(interaction)\n",
    "\n",
    "                else:\n",
    "                    if len(matching) >= 2:  \n",
    "                        cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                        interaction_genes.append(interaction)\n",
    "\n",
    "    interactions_in_bp[i] = cluster_hits\n",
    "    interaction_genes_only[i] = interaction_genes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(unique_per_cluster_set, unique_per_cluster):\n",
    "    diff = (i - j).union(j - i)\n",
    "    print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82355d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not just unique bps but all or common over x number of clusters\n",
    "\n",
    "#split BP & MF\n",
    "\n",
    "#builds a dictionary mapping each GO term to the set of clusters it appears in\n",
    "go_to_clusters = {}\n",
    "for cluster, series in genes_bps_sep.items():\n",
    "    for go_term in series.index:\n",
    "        go_to_clusters.setdefault(go_term, set()).add(cluster)\n",
    "print(go_to_clusters)\n",
    "\n",
    "#filtering for no. of clusterrs\n",
    "valid_go_terms = {go for go, clusters in go_to_clusters.items() if len(clusters) <= 1}\n",
    "print(valid_go_terms)\n",
    "\n",
    "#OR filtering manually?\n",
    "#valid_go_terms = {go for go, clusters in go_to_clusters.items() if in go_terms_to_use}\n",
    "\n",
    "genes_bps_sep_filtered = {\n",
    "    cluster: series[series.index.isin(valid_go_terms)]\n",
    "    for cluster, series in genes_bps_sep.items()\n",
    "}\n",
    "\n",
    "genes_only = {\n",
    "    cluster: sorted(set(gene for genes in series.values for gene in genes))\n",
    "    for cluster, series in genes_bps_sep_filtered.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ebb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'collagen binding involved in cell-matrix adhesion': {3, 4},\n",
    "#'fibroblast proliferation': {5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f59468",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df_filtered = pd.DataFrame()\n",
    "for i, thing in genes_bps_sep_filtered.items():\n",
    "    #print(thing)\n",
    "    dfff_filtered = pd.DataFrame(data = thing)\n",
    "    dfff_filtered[\"cluster\"] = i\n",
    "    big_df_filtered = pd.concat((big_df_filtered, dfff_filtered))\n",
    "big_df_filtered\n",
    "\n",
    "big_df = pd.DataFrame()\n",
    "for i, thing in genes_bps_sep.items():\n",
    "    print(thing)\n",
    "    dfff = pd.DataFrame(data = thing)\n",
    "    dfff[\"cluster\"] = i\n",
    "    big_df = pd.concat((big_df, dfff))\n",
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints last interaction genes only, so can be either BP or MF depending on what i last ran\n",
    "#for i, val in interaction_genes_only.items():\n",
    "#    print(len(set(val)))\n",
    "\n",
    "#for the cluster no. = n function\n",
    "for i, val in genes_only.items():\n",
    "    print(len(set(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCC_lrscoress = RCC_lrscores[[\"LRScore\", \"lr_pair\", \"source\", \"target\"]]\n",
    "RCC_lrscoress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged = merged[merged[\"same_direction\"] == True].drop_duplicates()\n",
    "subsetmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trend_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in cluster_dict.items():\n",
    "    opt3 = \"intra\"\n",
    "\n",
    "    if opt3 == \"intra\":\n",
    "        subset_RCC = subsetmerged_RCC[(subsetmerged_RCC[\"cluster_s\"] == name) & (subsetmerged_RCC[\"cluster_t\"] == name)]\n",
    "        subset_MF = subsetmerged_MF[(subsetmerged_MF[\"cluster_s\"] == name) & (subsetmerged_MF[\"cluster_t\"] == name)]  \n",
    "    elif opt3 == \"inter\":\n",
    "        subset_RCC = subsetmerged_RCC[~((subsetmerged_RCC[\"cluster_s\"] == name) & (subsetmerged_RCC[\"cluster_t\"] == name))]\n",
    "        subset_MF = subsetmerged_MF[~((subsetmerged_MF[\"cluster_s\"] == name) & (subsetmerged_MF[\"cluster_t\"] == name))]  \n",
    "        \n",
    "          \n",
    "    #print(subset_RCC)\n",
    "    subsetmerged_RCC_s = subset_RCC[subset_RCC[\"source\"].isin(i)] \n",
    "    subsetmerged_RCC_t = subset_RCC[subset_RCC[\"target\"].isin(i)]\n",
    "\n",
    "                                      \n",
    "    subsetmerged_MF_s = subset_MF[subset_MF[\"source\"].isin(i)]\n",
    "    subsetmerged_MF_t = subset_MF[subset_MF[\"target\"].isin(i)]\n",
    "\n",
    "    if opt3 == \"intra\":\n",
    "        print(\"RCC\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_RCC_s,threshold = 50, plt_name = f\"RCC {name}\")\n",
    "        print(\"MF\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_MF_s, threshold=50, plt_name = f\"MF {name}\")\n",
    "\n",
    "    elif opt3 == \"inter\":\n",
    "        print(\"RCC\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_RCC_s,threshold = 100, plt_name = f\"RCC {name}\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_RCC_t,threshold = 100, plt_name = f\"RCC  {name}\")\n",
    "        print(\"MF\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_MF_s, threshold=100, plt_name = f\"MF {name}\")\n",
    "        pycrosstalker.pl.plot_sankey(subsetmerged_MF_t, threshold=100, plt_name = f\"MF {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.colors as pc\n",
    "import plotly.graph_objects as go\n",
    "from plotnine import *\n",
    "from adjustText import adjust_text\n",
    "from gprofiler import GProfiler\n",
    "from sankeyflow import Sankey\n",
    "\n",
    "\n",
    "\n",
    "def plot_sankey(lrobj_tbl, target=None, ligand_cluster=None, receptor_cluster=None,\n",
    "                plt_name=None, threshold=50, tfflag=True):\n",
    "    \"\"\"\n",
    "    Generate celltypeligandreceptorcelltype Sankey diagram.\n",
    "\n",
    "    This function selected genes sankey plot\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    lrobj_tbl :\n",
    "        LRobject table with all data\n",
    "\n",
    "    target :\n",
    "        gene\n",
    "\n",
    "    ligand_cluster :\n",
    "        Ligand Clusters\n",
    "\n",
    "    receptor_cluster :\n",
    "        Receptor Clusters\n",
    "\n",
    "    plt_name :\n",
    "        plot title\n",
    "\n",
    "    threshold :\n",
    "        top_n n value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Python default plot\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    lrobj_tbl = lrobj_tbl[(lrobj_tbl['type_gene_A'] == \"Ligand\") & (lrobj_tbl['type_gene_B'] == \"Receptor\")]\n",
    "    print(lrobj_tbl)\n",
    "\n",
    "    lrobj_tbl['gene_A'] = lrobj_tbl['gene_A'].astype(str) + '|L'\n",
    "    lrobj_tbl['gene_B'] = lrobj_tbl['gene_B'].astype(str) + '|R'\n",
    "\n",
    "    if target is not None:\n",
    "        if len(target.split('|')) > 1:\n",
    "            target_type = str(target.split('|')[1])\n",
    "            if target_type == 'R':\n",
    "                if lrobj_tbl['gene_B'].str.contains('\\\\|').any():\n",
    "                    pass\n",
    "                else:\n",
    "                    target = target.split('|')[0]\n",
    "                data = lrobj_tbl[lrobj_tbl['gene_B'] == target]\n",
    "            elif target_type == 'L':\n",
    "                if lrobj_tbl['gene_A'].str.contains('\\\\|').any():\n",
    "                    pass\n",
    "                else:\n",
    "                    target = target.split('|')[0]\n",
    "                data = lrobj_tbl[lrobj_tbl['gene_A'] == target]\n",
    "        else:\n",
    "            data = lrobj_tbl[lrobj_tbl['allpair'].str.contains(target)]\n",
    "    else:\n",
    "        data = lrobj_tbl\n",
    "\n",
    "    \n",
    "    if ligand_cluster is not None:\n",
    "        data = data[data['source'].isin(ligand_cluster)]\n",
    "    \n",
    "    if receptor_cluster is not None:\n",
    "        data = data[data['target'].isin(receptor_cluster)]\n",
    "\n",
    "    color_palette = ['#00BFC4', '#FF3E3E']\n",
    "\n",
    "    \n",
    "    if len(data) >= 1:\n",
    "        cat_cols = ['source', 'gene_A', 'gene_B', 'target']\n",
    "        value_cols = 'LRScore'\n",
    "\n",
    "        if len(data) < threshold:\n",
    "                data = data.loc[data['LRScore'].abs().nlargest().index]\n",
    "                \n",
    "        data = data.loc[data['LRScore'].abs().nlargest(min(len(data), threshold)).index]\n",
    "        title = plt_name\n",
    "\n",
    "        gen_sankey(data, cat_cols, value_cols, title)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Gene->{target} Not Found\")\n",
    "    \n",
    "\n",
    "def gen_sankey2(df, cat_cols=[], value_cols='', title='Sankey Diagram'):\n",
    "    \"\"\"\n",
    "    Helper function to the function plot_sankey()\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        Dataframe\n",
    "\n",
    "    cat_cols :\n",
    "        Columns interested in the sankey plot\n",
    "\n",
    "    value_cols :\n",
    "        Sankey plot generated using connections based on this value_cols\n",
    "\n",
    "    title :\n",
    "        Title of Sankey plot\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing (plots Sankey plot)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df['source'] += 'S'\n",
    "    df['target'] += 'T'\n",
    "    \n",
    "    labelList = []\n",
    "    for catCol in cat_cols:\n",
    "        labelListTemp =  list((df[catCol].values))\n",
    "        labelList = labelList + labelListTemp    \n",
    "        \n",
    "    for i in range(len(cat_cols)-1):\n",
    "        if i==0:\n",
    "            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            sourceTargetDf.columns = ['source','target','count']\n",
    "        else:\n",
    "            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            tempDf.columns = ['source','target','count']\n",
    "            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "        # sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n",
    "        \n",
    "    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n",
    "    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n",
    "\n",
    "    for i, label in enumerate(labelList):\n",
    "        if label[-1:] == 'S' or label[-1:] == 'T':\n",
    "            labelList[i] = labelList[i][:-1]\n",
    "        \n",
    "    norm = mcolors.Normalize(vmin=min(sourceTargetDf['count']), vmax=max(sourceTargetDf['count']))\n",
    "    colormap = cm.get_cmap('RdBu_r')\n",
    "    link_colors = [mcolors.to_hex(colormap(norm(value))) for value in sourceTargetDf['count']]\n",
    "    \n",
    "    fig =  go.Figure(data = [go.Sankey(\n",
    "        node = dict(\n",
    "          pad = 0,\n",
    "          thickness = 20,\n",
    "          line = dict(\n",
    "            color = \"black\",\n",
    "            width = 0.5\n",
    "          ),\n",
    "          label = labelList,\n",
    "          color = \"white\"\n",
    "        ),\n",
    "        link = dict(\n",
    "          source = sourceTargetDf['sourceID'],\n",
    "          target = sourceTargetDf['targetID'],\n",
    "          value = [abs(i) for i in sourceTargetDf['count']],\n",
    "          color = link_colors\n",
    "        )    \n",
    "    )])\n",
    "    \n",
    "    colorbar_trace = go.Scatter(\n",
    "        x=[None], y=[None], mode='markers',\n",
    "        marker=dict(\n",
    "            colorscale='RdBu_r',\n",
    "            cmin=min(sourceTargetDf['count']),\n",
    "            cmax=max(sourceTargetDf['count']),\n",
    "            colorbar=dict(\n",
    "                title=\"Value\",\n",
    "                thickness=15,\n",
    "                len=0.5,\n",
    "                x=1.05,\n",
    "                xref=\"paper\"\n",
    "            )\n",
    "        ),\n",
    "        hoverinfo='none'\n",
    "    )\n",
    "\n",
    "    fig.add_trace(colorbar_trace)\n",
    "\n",
    "    fig.add_annotation(x=0, y=1.05, yref=\"paper\", text=\"Source\", showarrow=False, font=dict(size=10))\n",
    "    fig.add_annotation(x=0.33, y=1.05, yref=\"paper\", text=\"Ligand\", showarrow=False, font=dict(size=10))\n",
    "    fig.add_annotation(x=0.66, y=1.05, yref=\"paper\", text=\"Receptor\", showarrow=False, font=dict(size=10))\n",
    "    fig.add_annotation(x=1, y=1.05, yref=\"paper\", text=\"Target\", showarrow=False, font=dict(size=10))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0,1]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0,1]),\n",
    "        plot_bgcolor='white',\n",
    "        autosize=True,\n",
    "        width = None,\n",
    "        height = 600,\n",
    "        title = title,\n",
    "        font = dict(size=10)\n",
    "        )\n",
    "    \n",
    "    fig.show(config={\"responsive\": True})\n",
    "\n",
    "def gen_sankey(df, cat_cols=[], value_cols='', title='Sankey Diagram', ligand_cluster = \"ligand\"):\n",
    "    \"\"\"\n",
    "    Helper function to the function plot_sankey()\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        Dataframe\n",
    "\n",
    "    cat_cols :\n",
    "        Columns interested in the sankey plot\n",
    "\n",
    "    value_cols :\n",
    "        Sankey plot generated using connections based on this value_cols\n",
    "\n",
    "    title :\n",
    "        Title of Sankey plot\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing (plots Sankey plot)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # df['source'] += 'S'\n",
    "    df['target'] += ' '\n",
    "    \n",
    "    labelList = []\n",
    "    for catCol in cat_cols:\n",
    "        labelListTemp =  list((df[catCol].values))\n",
    "        labelList = labelList + labelListTemp    \n",
    " \n",
    "    for i in range(len(cat_cols)-1):\n",
    "        if i==0:\n",
    "            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            sourceTargetDf.columns = ['source','target','count']\n",
    "        else:\n",
    "            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            tempDf.columns = ['source','target','count']\n",
    "            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "\n",
    "\n",
    "    vmin = sourceTargetDf['count'].min()\n",
    "    vmax = sourceTargetDf['count'].max()\n",
    "    limit = max(abs(vmin), abs(vmax))\n",
    "    vcenter = 0\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-limit, vcenter=vcenter, vmax=limit)\n",
    "    # norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = plt.get_cmap('RdBu_r')\n",
    "    sourceTargetDf['hex_color'] = sourceTargetDf['count'].apply(lambda x: mcolors.to_hex(cmap(norm(x))))\n",
    "    #df_fixed = preprocess_cellchat_sankey(sourceTargetDf)\n",
    "    #print(df_fixed)\n",
    "\n",
    "    flows = []\n",
    "    for i, row in sourceTargetDf.iterrows():\n",
    "        flows.append((row['source'], row['target'], 1, {'color': row['hex_color']}))\n",
    "\n",
    "\n",
    "    nodes = Sankey.infer_nodes(flows)\n",
    "    nodes = list(filter(lambda empt: empt, nodes))\n",
    "    print(flows)\n",
    "    print(nodes)\n",
    "    nodes_new = []\n",
    "    for level in nodes:\n",
    "        level_new = []\n",
    "        for node in level:\n",
    "            node_new = node + [{'color' : 'black',\n",
    "                                'label_pos':'center', 'label_opts': dict(fontsize=10, bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', \n",
    "                                facecolor='white'))}]\n",
    "            level_new.append(node_new)\n",
    "        nodes_new.append(level_new)\n",
    "    print(nodes_new)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    s = Sankey(flows=flows,\n",
    "               nodes=nodes_new,\n",
    "               flow_color_mode_alpha=0.3,\n",
    "               node_opts=dict(label_format='{label}')\n",
    "    )\n",
    "    s.draw(ax=ax)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', pad=0.01, shrink=0.5)\n",
    "    cbar.set_label(value_cols, fontsize=12)\n",
    "\n",
    "    ax.text(x=-0.05, y=1.02, s=\"Source\", fontsize=10)\n",
    "    ax.text(x=0.95, y=1.02, s=\"Ligand\", fontsize=10)\n",
    "    ax.text(x=1.95, y=1.02, s=\"Receptor\", fontsize=10)\n",
    "    ax.text(x=2.95, y=1.02, s=\"Target\", fontsize=10)\n",
    "\n",
    "    plt.savefig(f'{title}_sankey.pdf')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b925d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in cluster_dict.values():\n",
    "    subsetmerged_RCC_s = subsetmerged_RCC[subsetmerged_RCC[\"source\"].isin(i)]\n",
    "    subsetmerged_RCC_t = subsetmerged_RCC[subsetmerged_RCC[\"target\"].isin(i)]\n",
    "                                          \n",
    "    subsetmerged_MF_s = subsetmerged_MF[subsetmerged_MF[\"source\"].isin(i)]\n",
    "    subsetmerged_MF_t = subsetmerged_MF[subsetmerged_MF[\"target\"].isin(i)]\n",
    "\n",
    "\n",
    "    print(\"RCC\")\n",
    "    plot_sankey(subsetmerged_RCC_s,threshold = 50, plt_name = f\"RCC\")\n",
    "    plot_sankey(subsetmerged_RCC_t,threshold = 50, plt_name = f\"RCC\")\n",
    "    print(\"MF\")\n",
    "    plot_sankey(subsetmerged_MF_s, threshold=50, plt_name = f\"MF\")\n",
    "    plot_sankey(subsetmerged_MF_t, threshold=50, plt_name = f\"MF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79143f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaffb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetmerged_RCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d831d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split neg and pos GO input\n",
    "\n",
    "cluster_dict = {\n",
    "    k: [v.removeprefix(\"RCC_\").removeprefix(\"MF_\") for v in vals]\n",
    "    for k, vals in cluster_dict.items()\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    item: cluster\n",
    "    for cluster, items in cluster_dict.items()\n",
    "    for item in items\n",
    "}\n",
    "\n",
    "grouped_list_RCC = []\n",
    "grouped_list_MF = []\n",
    "# Apply to each dataframe in RCC_df_list\n",
    "\n",
    "RCC_split = RCC_diff_df.copy()\n",
    "RCC_split[\"cluster_t\"] = RCC_split[\"target\"].map(mapping)\n",
    "RCC_split[\"cluster_s\"] = RCC_split[\"source\"].map(mapping)\n",
    "\n",
    "\n",
    "grouped_RCC_split = RCC_split.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "    \"LRScore\": \"mean\"\n",
    "    })\n",
    "\n",
    "MF_split = MF_diff_df.copy()\n",
    "MF_split[\"cluster_t\"] = MF_split[\"target\"].map(mapping)\n",
    "MF_split[\"cluster_s\"] = MF_split[\"source\"].map(mapping)\n",
    "\n",
    "\n",
    "grouped_MF_split = MF_split.groupby([\"cluster_s\", \"cluster_t\", \"lr_pair\"], as_index=False).agg({\n",
    "    \"LRScore\": \"mean\"\n",
    "    })\n",
    "\n",
    "RCC_split_final = grouped_RCC_split.rename(columns={\"LRScore\": \"LRScore_RCC\"})\n",
    "MF_split_final = grouped_MF_split.rename(columns={\"LRScore\": \"LRScore_MF\"})\n",
    "\n",
    "RCC_split_final[\"direction_RCC\"] = RCC_split_final[\"LRScore_RCC\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")\n",
    "MF_split_final[\"direction_MF\"] = MF_split_final[\"LRScore_MF\"].apply(lambda x: \"pos\" if x > 0 else \"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCC_split_final_up = RCC_split_final[RCC_split_final[\"direction_RCC\"] == \"pos\"]\n",
    "RCC_split_final_down = RCC_split_final[RCC_split_final[\"direction_RCC\"] == \"neg\"]\n",
    "\n",
    "MF_split_final_up = MF_split_final[MF_split_final[\"direction_MF\"] == \"pos\"]\n",
    "MF_split_final_down = MF_split_final[MF_split_final[\"direction_MF\"] == \"neg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ba55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCC_split_GO = RCC.copy()\n",
    "RCC_split_GO[\"cluster_t\"] = RCC_split_GO[\"target\"].map(mapping)\n",
    "RCC_split_GO[\"cluster_s\"] = RCC_split_GO[\"source\"].map(mapping)\n",
    "\n",
    "MF_split_GO = MF.copy()\n",
    "MF_split_GO[\"cluster_t\"] = MF_split_GO[\"target\"].map(mapping)\n",
    "MF_split_GO[\"cluster_s\"] = MF_split_GO[\"source\"].map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8acacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCC_df_up = RCC_split_GO.merge(\n",
    "    RCC_split_final_up[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "    on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "RCC_df_down = RCC_split_GO.merge(\n",
    "    RCC_split_final_down[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "    on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "MF_df_up = MF_split_GO.merge(\n",
    "    MF_split_final_up[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "    on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "MF_df_down = MF_split_GO.merge(\n",
    "    MF_split_final_down[[\"cluster_s\", \"cluster_t\", \"lr_pair\"]],\n",
    "    on=[\"cluster_s\", \"cluster_t\", \"lr_pair\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy for split RCC and MF\n",
    "#1a,b,c(set) 2a,b,c(threshold) 3a,b,c(unique)  get all interactions\n",
    "#replace c with LR-L(downstream)\n",
    "#d is the same as c but is returning source and target genes together (fix that receptor complexes still need to be split)\n",
    "#add empty lists so that singleton clusters dont repeat genes\n",
    "\n",
    "def get_interactions_set_split(opt = \"set\", opt2 = \"a\", opt3 = \"up\"):\n",
    "    all_interactions_list = []\n",
    "    all_interactions_source_list = []\n",
    "    all_interactions_target_list = []\n",
    "    unique_per_cluster = []\n",
    "    unique_per_cluster_source = []\n",
    "    unique_per_cluster_target = []\n",
    "    test_clust = []\n",
    "    \n",
    "    if opt3 == \"up\":\n",
    "        RCC = RCC_df_up\n",
    "        MF = MF_df_up\n",
    "\n",
    "    elif  opt3 == \"down\":\n",
    "        RCC = RCC_df_down\n",
    "        MF = MF_df_down\n",
    "\n",
    "    for i in cluster_dict: \n",
    "        tst_clust = []\n",
    "        all_interactions = []\n",
    "        all_interactions_source = []\n",
    "        all_interactions_target = []\n",
    "        \n",
    "        #for clust in cluster_dict[i]:\n",
    "        #    if any(clust in vals for vals in stable_partners.values()):\n",
    "        #        tst_clust.append(clust)\n",
    "\n",
    "        for clust in cluster_dict[i]:\n",
    "            tst_clust.append(clust)\n",
    "            \n",
    "        print(tst_clust)\n",
    "        tst_clust = list(map(lambda x:  x.removeprefix(\"RCC_\").removeprefix(\"MF_\"), tst_clust))\n",
    "\n",
    "        if opt2 == \"a\" or opt2 == \"b\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust)\n",
    "\n",
    "        if opt2 == \"c\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts(MF, tst_clust)\n",
    "\n",
    "            downstreamL_RCC, _ = build_dicts_associated_gene(RCC, tst_clust)\n",
    "            downstreamL_MF, _ = build_dicts_associated_gene(MF, tst_clust)\n",
    "\n",
    "        if opt2 == \"d\" or opt2 == \"d2\":\n",
    "            clust_dict_source_RCC, clust_dict_target_RCC = build_dicts_associated_gene(RCC, tst_clust)\n",
    "            clust_dict_source_MF, clust_dict_target_MF = build_dicts_associated_gene(MF, tst_clust)\n",
    "\n",
    "        RCC_source_sets =  {cl: set(clust_dict_source_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_source_sets = {cl: set(clust_dict_source_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "\n",
    "        RCC_target_sets =  {cl: set(clust_dict_target_RCC[cl]) for cl in tst_clust if len(clust_dict_target_RCC[cl]) != 0}\n",
    "        MF_target_sets = {cl: set(clust_dict_target_MF[cl]) for cl in tst_clust if len(clust_dict_target_MF[cl]) != 0}\n",
    "\n",
    "        if opt == \"set\" or opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                \n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "\n",
    "            RCC_source_sets_interactions = []\n",
    "            RCC_target_sets_interactions = []\n",
    "            RCC_total_interactions = []\n",
    "            if len(RCC_target_sets) >= 1: \n",
    "                RCC_source_sets_interactions =  set.intersection(*RCC_source_sets.values())\n",
    "                RCC_target_sets_interactions =  set.intersection(*RCC_target_sets.values())\n",
    "                RCC_total_interactions = RCC_source_sets_interactions.union(RCC_target_sets_interactions)\n",
    "                #print(RCC_target_sets)\n",
    "                #print(RCC_target_sets_interactions)\n",
    "\n",
    "            MF_source_sets_interactions = []\n",
    "            MF_target_sets_interactions = []\n",
    "            MF_total_interactions = []\n",
    "            if len(MF_target_sets) >= 1: \n",
    "                MF_source_sets_interactions =  set.intersection(*MF_source_sets.values())\n",
    "                MF_target_sets_interactions =  set.intersection(*MF_target_sets.values())\n",
    "                MF_total_interactions = MF_source_sets_interactions.union(MF_target_sets_interactions)\n",
    "\n",
    "            if opt2 == \"a\" or opt2 ==\"d\":\n",
    "                if len(RCC_total_interactions) > 1 and len(MF_total_interactions) > 1: \n",
    "                    all_interactions = RCC_total_interactions.intersection(MF_total_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 == \"b\"  or opt2 == \"d2\":\n",
    "                if len(MF_source_sets_interactions) > 1 or len(RCC_source_sets_interactions) > 1: \n",
    "                    all_interactions_source = RCC_source_sets_interactions.intersection(MF_source_sets_interactions)\n",
    "                    all_interactions_target = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "                \n",
    "            if opt2 == \"c\":\n",
    "                if len(MF_target_sets_interactions) > 1 and len(RCC_target_sets_interactions) > 1: \n",
    "                    all_interactions = RCC_target_sets_interactions.intersection(MF_target_sets_interactions)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                \n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "        ###########################################################################################################  \n",
    "        if opt == \"threshold\":\n",
    "\n",
    "            if opt2 == \"c\":\n",
    "\n",
    "                downstreamL_RCC = {cl: set(downstreamL_RCC[cl]) for cl in tst_clust if len(downstreamL_RCC[cl]) != 0}\n",
    "                downstreamL_MF = {cl: set(downstreamL_MF[cl]) for cl in tst_clust if len(downstreamL_MF[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                RCC_target_sets= {\n",
    "                cl: RCC_target_sets.get(cl, set()) | downstreamL_RCC.get(cl, set())\n",
    "                    for cl in downstreamL_RCC.keys() if len(downstreamL_RCC[cl]) != 0}\n",
    "                #print(downstreamL_RCC)\n",
    "\n",
    "                MF_target_sets = {\n",
    "                cl: MF_target_sets.get(cl, set()) | downstreamL_MF.get(cl, set())\n",
    "                for cl in downstreamL_MF.keys()  if len(downstreamL_MF[cl]) != 0}\n",
    "                \n",
    "                #RCC_target_sets = {k: set(v) for k, v in RCC_target_sets.items()}\n",
    "                #MF_target_sets = {k: set(v) for k, v in MF_target_sets.items()}\n",
    "                \n",
    "            RCC_source_sets_list = list(RCC_source_sets.values())\n",
    "            MF_source_sets_list = list(MF_source_sets.values())\n",
    "            RCC_target_sets_list = list(RCC_target_sets.values())\n",
    "            MF_target_sets_list = list(MF_target_sets.values())\n",
    "\n",
    "            threshold = 0.8  # 80%\n",
    "\n",
    "            source_interactions_RCC = threshold_intersection(RCC_source_sets_list, threshold) if len(RCC_source_sets_list) > 0 else set()\n",
    "            target_interactions_RCC = threshold_intersection(RCC_target_sets_list, threshold) if len(RCC_target_sets_list) > 0 else set()\n",
    "\n",
    "            source_interactions_MF = threshold_intersection(MF_source_sets_list, threshold) if len(MF_source_sets_list) > 0 else set()\n",
    "            target_interactions_MF = threshold_intersection(MF_target_sets_list, threshold) if len(MF_target_sets_list) > 0 else set()\n",
    "\n",
    "            all_interactions_RCC = source_interactions_RCC.union(target_interactions_RCC) if len(source_interactions_RCC) > 0 else set()\n",
    "            all_interactions_MF = source_interactions_MF.union(target_interactions_MF) if len(source_interactions_MF) > 0 else set()\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\":\n",
    "                all_interactions = all_interactions_RCC.intersection(all_interactions_MF) if (len(all_interactions_MF) > 0 & len(all_interactions_RCC)) else set()\n",
    "                #all_interactions = list(threshold_intersection([all_interactions_RCC, all_interactions_MF]) if len(all_interactions_MF) > 0 else set())\n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "        \n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                if len(source_interactions_MF) > 1 or len(source_interactions_RCC) > 1: \n",
    "                    all_interactions_source = source_interactions_RCC.intersection(source_interactions_MF)\n",
    "                    all_interactions_target = target_interactions_RCC.intersection(target_interactions_MF)\n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "\n",
    "                all_interactions_source_list.append(all_interactions_source)\n",
    "                all_interactions_target_list.append(all_interactions_target)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "            if opt2 ==\"c\":\n",
    "                if len(target_interactions_MF) > 1 and len(target_interactions_RCC) > 1: \n",
    "                    all_interactions = target_interactions_RCC.intersection(target_interactions_MF)  \n",
    "                else:\n",
    "                    all_interactions = set()\n",
    "                \n",
    "                all_interactions_list.append(all_interactions)\n",
    "                test_clust.append(tst_clust)\n",
    "\n",
    "     \n",
    "    if opt == \"unique\":\n",
    "\n",
    "            if opt2 == \"a\" or opt2 == \"d\" or opt2 == \"c\":\n",
    "                for i, clustergenes in enumerate(all_interactions_list):\n",
    "                    #print(len(cluster))\n",
    "                    if len(clustergenes) > 0:\n",
    "                        #print(\"clustergenes\", clustergenes)\n",
    "                        set_i = set(clustergenes)  # interactions in this cluster\n",
    "                        #print(\"set_i\", set_i)\n",
    "                        others = set().union(*[all_interactions_list[j] for j in range(len(all_interactions_list)) if j != i])\n",
    "                        unique = set_i - others  # LRs only in this cluster\n",
    "                        #print(\"unique\", unique)\n",
    "                        unique_per_cluster.append(unique)\n",
    "                    else:\n",
    "                        unique_per_cluster.append(set())\n",
    "\n",
    "            if opt2 == \"b\" or opt2 == \"d2\":\n",
    "                 \n",
    "                for i, cluster in enumerate(all_interactions_source_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_source_list[j] for j in range(len(all_interactions_source_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_source.append(unique)\n",
    "\n",
    "                for i, cluster in enumerate(all_interactions_target_list):\n",
    "                    set_i = set(cluster)  # interactions in this cluster\n",
    "                    others = set().union(*[all_interactions_target_list[j] for j in range(len(all_interactions_target_list)) if j != i])\n",
    "                    unique = set_i - others  # LRs only in this cluster\n",
    "                    unique_per_cluster_target.append(unique)\n",
    "\n",
    "\n",
    "    if opt2 == \"a\" or opt2 ==\"c\" or opt2 == \"d\":\n",
    "        if opt == \"set\" or opt == \"threshold\":        \n",
    "            return all_interactions_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            return unique_per_cluster, test_clust\n",
    "        \n",
    "    if opt2 == \"b\" or opt2 == \"d2\":\n",
    "        if opt == \"set\" or opt == \"threshold\":        \n",
    "            return all_interactions_source_list, all_interactions_target_list, test_clust\n",
    "        if opt == \"unique\":\n",
    "            return unique_per_cluster_source, unique_per_cluster_target, test_clust\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst, clusters_cleaned = get_interactions_set_split(opt=\"set\", opt2=\"c\", opt3= \"down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b087bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_interactions = tst\n",
    "df_full = pd.DataFrame()\n",
    "top_terms_list = []\n",
    "\n",
    "for i in range(len(all_interactions)):\n",
    "    markers_tst = list(all_interactions[i])\n",
    "\n",
    "    s = \"_\"\n",
    "    clust_name = s.join(clusters[i]).replace(\"/\", \"_\")\n",
    "    print(clust_name)\n",
    "    print(clusters[i])\n",
    "    pre_genes = []\n",
    "    for m in markers_tst:\n",
    "        splitt = m.split(\"_\")\n",
    "        pre_genes.append(splitt)\n",
    "\n",
    "    genes = []\n",
    "    for xs in pre_genes:\n",
    "        for x in xs:\n",
    "            genes.append(x)\n",
    "            \n",
    "    genes = list(np.unique(genes))\n",
    "\n",
    "    mg = mygene.MyGeneInfo()\n",
    "\n",
    "    res = mg.querymany(\n",
    "        genes,\n",
    "        scopes=\"symbol\",\n",
    "        fields=\"entrezgene,ensembl.gene,go\",\n",
    "        species=\"human\"\n",
    "    )\n",
    "\n",
    "    for r in res:\n",
    "        print(r[\"query\"], \"\", r.get(\"entrezgene\"))\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    for r in res:\n",
    "        geneid = r.get(\"entrezgene\")\n",
    "        genename = r.get(\"symbol\", r[\"query\"]) \n",
    "        if geneid is None or \"go\" not in r:\n",
    "            continue\n",
    "        gos = r[\"go\"]\n",
    "        if isinstance(gos, dict):\n",
    "            for ns, terms in gos.items():  # ns = BP, MF, CC\n",
    "                if isinstance(terms, list):\n",
    "                    for t in terms:\n",
    "                        rows.append({\"Gene\": genename, \"GeneID\": geneid, \"GOID\": t[\"id\"], \"Namespace\": ns, \"GOName\": t[\"term\"]})\n",
    "                elif isinstance(terms, dict):\n",
    "                    rows.append({\"Gene\": genename, \"GeneID\": geneid, \"GOID\": terms[\"id\"], \"Namespace\": ns, \"GOName\": terms[\"term\"]})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    if not df.empty:\n",
    "         df = df[df[\"GOID\"].isin(allowed_terms)]\n",
    "         df = df[~df[\"GOName\"].isin(filtered_out_terms)]\n",
    "         df = df[df[\"GOName\"].str.contains(\"pathway\")==False]\n",
    "         df = df[df[\"GOName\"].str.contains(\"cardiac\")==False]\n",
    "         df = df[df[\"GOName\"].str.contains(\"thymic\")==False]\n",
    "\n",
    "    df_full = pd.concat((df_full, df))\n",
    "\n",
    "    if df.empty:\n",
    "        top_terms_list.append(set())\n",
    "        continue\n",
    "    go_counts = df.groupby([\"Namespace\", \"GOID\", \"GOName\"]).count().rename(columns={\"GeneID\": \"GeneCount\"}).reset_index()\n",
    "\n",
    "\n",
    "    for ns in [\"BP\"]:#, \"MF\"]:#, \"CC\"]:\n",
    "     \n",
    "        top_terms = go_counts[go_counts.Namespace==ns].sort_values(\"GeneCount\", ascending=False).head(30)\n",
    "        \n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(\n",
    "            data=top_terms,\n",
    "            y=\"GOName\",\n",
    "            x=\"GeneCount\",\n",
    "            palette=\"viridis\"\n",
    "        )\n",
    "        top_terms_list.append(top_terms[\"GOName\"])\n",
    "\n",
    "        plt.xlabel(\"Number of Genes\")\n",
    "        plt.ylabel(f\"GO {ns} Terms\")\n",
    "        #plt.title(f\"{clust_name}\")\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1a_common_LRs_cluster_all_LR_pairs_unchanged/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1b_common_LRs_cluster_separate_incoming_outgoing/incoming/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1b_common_LRs_cluster_separate_incoming_outgoing/outgoing/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/incoming/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/outgoing/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"/home/larissa/Documents/Masterarbeit/plots/GO/1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform/set/RBERVertex/{clust_name}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\1c_common_LRs_cluster_only_genes_associated_with_celltypes_GO_konform\\\\set\\\\RBERVertex\\\\unique\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res025\\\\unique\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res031\\\\unique_c\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "        #plt.savefig(f\"D:\\\\studium\\\\Masterarbeit\\\\plots\\\\GO\\\\res031\\\\unique_d\\\\{clusters[i][0]}_top_20_BPs_GO.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_bp = df_full[df_full[\"Namespace\"] == \"BP\"]\n",
    "df_full_bp = df_full_bp[[\"Gene\", \"GOName\"]]\n",
    "df_full_bp\n",
    "#df_full_bp.pivot(index=\"GOName\", columns=\"Gene\")\n",
    "genes_bps = df_full_bp.groupby(\"GOName\")[\"Gene\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "#get bp terms that only appear in one single cluster\n",
    "unique_per_cluster = []\n",
    "\n",
    "#the <2 not important here, just didnt delete bc i copied it from the unique genes function\n",
    "for i, cluster in enumerate(top_terms_list):\n",
    "    if len(clusters[i]) < 2:\n",
    "        unique_per_cluster.append([])\n",
    "        continue\n",
    "    set_i = set(cluster)  # interactions in this cluster\n",
    "    others = set().union(*[top_terms_list[j]for j in range(len(top_terms_list)) if j != i])\n",
    "    unique = set_i - others  # LRs only in this cluster\n",
    "    unique_per_cluster.append(unique)\n",
    "\n",
    "for idx, uniq in enumerate(unique_per_cluster):\n",
    "    print(f\"Cluster {idx}: {uniq}\")\n",
    "    \n",
    "\n",
    "genes_bps_sub = genes_bps[genes_bps.index.isin(flatten(unique_per_cluster))]\n",
    "print(genes_bps_sub)\n",
    "\n",
    "#doesnt check if lr pair is in cluster if using methods 1c where genes are already split\n",
    "#knnen einfach einzeln da sein\n",
    "method= \"d\"\n",
    "\n",
    "interactions_in_bp = {}\n",
    "interaction_genes_only = {}\n",
    "\n",
    "\n",
    "for i, lr_sets in enumerate(all_interactions):\n",
    "    if not (lr_sets):\n",
    "        continue\n",
    "    cluster_hits = []\n",
    "    interaction_genes = []\n",
    "    #print(unique_per_cluster[i])\n",
    "    for j in unique_per_cluster[i]:\n",
    "        \n",
    "        bps_of_interest = [j]\n",
    "\n",
    "        #print(bps_of_interest)\n",
    "        genes_bps_sub = genes_bps[genes_bps.index.isin(bps_of_interest)]\n",
    "        #print(genes_bps_sub)\n",
    "        \n",
    "        \n",
    "        for interaction in lr_sets:\n",
    "            # split lr into ligand and receptor\n",
    "            if \"_\" in interaction:\n",
    "                genes = interaction.split(\"_\")\n",
    "            else:\n",
    "                genes = [interaction]\n",
    "            #print(genes)\n",
    "            for bp, genes_in_bp in genes_bps_sub.items():\n",
    "                if not isinstance(genes_in_bp, set):\n",
    "                    genes_in_bp = set(genes_in_bp)\n",
    "\n",
    "                #print(genes_in_bp)\n",
    "                # are both l and r in this biological process\n",
    "                matching = [g for g in genes if g in genes_in_bp]\n",
    "                #matching = [(g, \"ligand\" if idx==0 else \"receptor\") \n",
    "                #     for idx, g in enumerate(genes) if g in genes_in_bp]\n",
    "                #print(matching)\n",
    "                # if both ligand and receptor are in this BP then keep\n",
    "                if method == \"d\":\n",
    "                    if len(matching) >= 1:  \n",
    "                        cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                        interaction_genes.append(interaction)\n",
    "\n",
    "                else:\n",
    "                    if len(matching) >= 2:  \n",
    "                        cluster_hits.append((clusters[i], interaction, bp, matching))\n",
    "                        interaction_genes.append(interaction)\n",
    "\n",
    "    interactions_in_bp[i] = cluster_hits\n",
    "    interaction_genes_only[i] = interaction_genes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb07116",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_terms = {}\n",
    "\n",
    "for entry in res:\n",
    "    gene_name = entry.get(\"query\") \n",
    "    terms = set()\n",
    "    \n",
    "    go_data = entry.get(\"go\", {})\n",
    "    for category, items in go_data.items():\n",
    "        for item in items:\n",
    "            if \"term\" in item:\n",
    "                terms.add(item[\"term\"])\n",
    "    \n",
    "    gene_to_terms[gene_name] = terms\n",
    "\n",
    "# Example output\n",
    "for gene, terms in gene_to_terms.items():\n",
    "    print(f\"{gene}: {terms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ddead",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "res = mg.querymany(\n",
    "    genes,\n",
    "    scopes=\"symbol\",\n",
    "    fields=\"ensembl\",\n",
    "    species=\"human\"\n",
    ")\n",
    "ensembl_ids = []\n",
    "for i in range(0, len(res)):\n",
    "    try:\n",
    "        ensembl_ids.append(res[i][\"ensembl\"][\"gene\"])\n",
    "    except TypeError:\n",
    "        ensembl_ids.append(res[i][\"ensembl\"][0][\"gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b32532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
